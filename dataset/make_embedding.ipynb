{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from sentence-transformers) (2.0.0)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.15.1 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: Pillow in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Collecting filelock (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.15.1->sentence-transformers)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp311-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.0-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/167.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl (410 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.3/410.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, pyyaml, networkx, joblib, fsspec, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed filelock-3.15.4 fsspec-2024.6.0 huggingface-hub-0.23.4 joblib-1.4.2 mpmath-1.3.0 networkx-3.3 pyyaml-6.0.1 regex-2024.5.15 safetensors-0.4.3 scikit-learn-1.5.0 scipy-1.13.1 sentence-transformers-3.0.1 sympy-1.12.1 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 tqdm-4.66.4 transformers-4.41.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: apt-get: command not found\n",
      "Collecting mecab-python3\n",
      "  Downloading mecab_python3-1.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Downloading mecab_python3-1.0.9-cp311-cp311-macosx_11_0_arm64.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mecab-python3\n",
      "Successfully installed mecab-python3-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!apt-get install mecab mecab-ipadic-utf8 python-mecab libmecab-dev\n",
    "!pip install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fugashi\n",
      "  Downloading fugashi-1.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Downloading fugashi-1.3.2-cp311-cp311-macosx_11_0_arm64.whl (513 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.1/513.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fugashi\n",
      "Successfully installed fugashi-1.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fugashi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ginza\n",
      "  Downloading ginza-5.2.0-py3-none-any.whl.metadata (448 bytes)\n",
      "Collecting spacy<4.0.0,>=3.4.4 (from ginza)\n",
      "  Downloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting plac>=1.3.3 (from ginza)\n",
      "  Downloading plac-1.4.3-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting SudachiPy<0.7.0,>=0.6.2 (from ginza)\n",
      "  Downloading SudachiPy-0.6.8-cp311-cp311-macosx_10_12_universal2.whl.metadata (12 kB)\n",
      "Collecting SudachiDict-core>=20210802 (from ginza)\n",
      "  Downloading SudachiDict_core-20240409-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ginza) (2.0.0)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached pydantic_core-2.18.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ginza) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ginza) (2024.6.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->ginza) (2.1.5)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading marisa_trie-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza) (2.18.0)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ginza)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading ginza-5.2.0-py3-none-any.whl (21 kB)\n",
      "Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
      "Downloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading SudachiPy-0.6.8-cp311-cp311-macosx_10_12_universal2.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic_core-2.18.4-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl (488 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.4/488.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: SudachiPy, plac, cymem, wrapt, wasabi, SudachiDict-core, spacy-loggers, spacy-legacy, shellingham, pydantic-core, numpy, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, annotated-types, srsly, smart-open, pydantic, preshed, markdown-it-py, language-data, blis, rich, langcodes, confection, typer, thinc, weasel, spacy, ginza\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "Successfully installed SudachiDict-core-20240409 SudachiPy-0.6.8 annotated-types-0.7.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 ginza-5.2.0 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.10 numpy-1.26.4 plac-1.4.3 preshed-3.0.9 pydantic-2.7.4 pydantic-core-2.18.4 rich-13.7.1 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.12.3 wasabi-1.1.3 weasel-0.4.1 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fugashi in /Users/abetaichi/master/app/.venv/lib/python3.11/site-packages (1.3.2)\n",
      "Collecting ipadic\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
      "  Building wheel for ipadic (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=4394ad2490c24f9fb9fba7cb7b254c980f87c8145ddab409e43c8198d2fc449a\n",
      "  Stored in directory: /Users/abetaichi/Library/Caches/pip/wheels/44/56/37/f543963822b85260c9f948df8fac8c20169c80dc71b24dc407\n",
      "Successfully built ipadic\n",
      "Installing collected packages: ipadic\n",
      "Successfully installed ipadic-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fugashi ipadic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_title</th>\n",
       "      <th>search_authors</th>\n",
       "      <th>search_publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>published_date</th>\n",
       "      <th>description</th>\n",
       "      <th>page_count</th>\n",
       "      <th>categories</th>\n",
       "      <th>language</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>use_title</th>\n",
       "      <th>use_author</th>\n",
       "      <th>use_publisher</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A/Bテスト実践ガイド　真のデータドリブンへ至る信用できる実験とは</td>\n",
       "      <td>Ron Kohavi，Diane Tang，Ya Xu，大杉直也</td>\n",
       "      <td>ドワンゴ</td>\n",
       "      <td>A/Bテスト実践ガイド</td>\n",
       "      <td>Ron Kohavi, Diane Tang, Ya Xu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-03</td>\n",
       "      <td>経営層からデータサイエンティスト、エンジニアまで全関係者必読の教科書!...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=EyRjz...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIエンジニアのための機械学習システムデザインパターン</td>\n",
       "      <td>澁井雄介</td>\n",
       "      <td>翔泳社</td>\n",
       "      <td>AIエンジニアのための機械学習システムデザインパターン</td>\n",
       "      <td>澁井 雄介</td>\n",
       "      <td>翔泳社</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>機械学習システム構築に必要な デザインパターンがここにある！ 【本書の背景】 Pythonを...</td>\n",
       "      <td>442.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=88ArE...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI・データ分析プロジェクトのすべて[ビジネス力×技術力=価値創出]</td>\n",
       "      <td>大城信晃，マスクド・アナライズ，伊藤徹郎，小西哲平，西原成輝</td>\n",
       "      <td>技術評論社</td>\n",
       "      <td>AI・データ分析プロジェクトのすべて</td>\n",
       "      <td>大城信晃, マスクド・アナライズ, 伊藤徹郎, 小西哲平, 西原成輝, 油井志郎</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>現場でしか得られないビジネス知識/暗黙知を解説。課題設定→案件獲得→外注見積→契約→分析手法...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=s4Idz...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI白書2019</td>\n",
       "      <td>独立行政法人情報処理推進機構AI白書編集委員会</td>\n",
       "      <td>KADOKAWA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWS運用入門 押さえておきたいAWSの基本と運用ノウハウ</td>\n",
       "      <td>佐竹陽一，山﨑翔平，小倉大，峯侑資</td>\n",
       "      <td>SBクリエイティブ</td>\n",
       "      <td>AWS運用入門</td>\n",
       "      <td>佐竹陽一, 山﨑翔平, 小倉大, 峯侑資</td>\n",
       "      <td>SBクリエイティブ</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>現場で役立つ！ AWSトップエンジニアが実践しているシステム運用の手法とコツ ※この電子書籍...</td>\n",
       "      <td>507.0</td>\n",
       "      <td>Computers</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=Dnm1E...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>音声認識</td>\n",
       "      <td>篠田浩一</td>\n",
       "      <td>講談社</td>\n",
       "      <td>音声認識</td>\n",
       "      <td>篠田浩一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>基礎理論はコンパクトにまとめ、「耐雑音」「話者認識」「深層学習」についてたっぷり解説。音声認...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=tH9ns...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>高次元の統計学</td>\n",
       "      <td>青嶋誠，矢田和善</td>\n",
       "      <td>共立出版</td>\n",
       "      <td>高次元の統計学</td>\n",
       "      <td>青嶋誠, 矢田和善</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=ZnI6x...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>ＬａＴｅＸ超入門　ゼロからはじめる理系の文書作成術</td>\n",
       "      <td>水谷正大</td>\n",
       "      <td>講談社</td>\n",
       "      <td>LaTeX超入門</td>\n",
       "      <td>水谷正大</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>理系のレポート作成や論文執筆の定番「LaTeX」の使い方が一冊でわかる!これだけ読めばレポー...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=nHWyz...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>ＬａＴｅＸ超入門　ゼロからはじめる理系の文書作成術</td>\n",
       "      <td>水谷正大</td>\n",
       "      <td>講談社</td>\n",
       "      <td>LaTeX超入門</td>\n",
       "      <td>水谷正大</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>理系のレポート作成や論文執筆の定番「LaTeX」の使い方が一冊でわかる!これだけ読めばレポー...</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=nHWyz...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Ｐｙｔｈｏｎで学ぶアルゴリズムとデータ構造</td>\n",
       "      <td>下平英寿，辻真吾</td>\n",
       "      <td>講談社</td>\n",
       "      <td>Ｐｙｔｈｏｎで学ぶアルゴリズムとデータ構造</td>\n",
       "      <td>辻真吾, 下平英寿</td>\n",
       "      <td>講談社</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>現代社会を支える根幹技術をPythonで！ Pythonプログラミングのスキルアップにも最適...</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Computers</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=sdnND...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           search_title                    search_authors  \\\n",
       "0     A/Bテスト実践ガイド　真のデータドリブンへ至る信用できる実験とは  Ron Kohavi，Diane Tang，Ya Xu，大杉直也   \n",
       "1           AIエンジニアのための機械学習システムデザインパターン                              澁井雄介   \n",
       "2    AI・データ分析プロジェクトのすべて[ビジネス力×技術力=価値創出]    大城信晃，マスクド・アナライズ，伊藤徹郎，小西哲平，西原成輝   \n",
       "3                              AI白書2019           独立行政法人情報処理推進機構AI白書編集委員会   \n",
       "4         AWS運用入門 押さえておきたいAWSの基本と運用ノウハウ                 佐竹陽一，山﨑翔平，小倉大，峯侑資   \n",
       "..                                  ...                               ...   \n",
       "385                                音声認識                              篠田浩一   \n",
       "386                             高次元の統計学                          青嶋誠，矢田和善   \n",
       "387           ＬａＴｅＸ超入門　ゼロからはじめる理系の文書作成術                              水谷正大   \n",
       "388           ＬａＴｅＸ超入門　ゼロからはじめる理系の文書作成術                              水谷正大   \n",
       "389               Ｐｙｔｈｏｎで学ぶアルゴリズムとデータ構造                          下平英寿，辻真吾   \n",
       "\n",
       "    search_publisher                        title  \\\n",
       "0               ドワンゴ                  A/Bテスト実践ガイド   \n",
       "1                翔泳社  AIエンジニアのための機械学習システムデザインパターン   \n",
       "2              技術評論社           AI・データ分析プロジェクトのすべて   \n",
       "3           KADOKAWA                          NaN   \n",
       "4          SBクリエイティブ                      AWS運用入門   \n",
       "..               ...                          ...   \n",
       "385              講談社                         音声認識   \n",
       "386             共立出版                      高次元の統計学   \n",
       "387              講談社                     LaTeX超入門   \n",
       "388              講談社                     LaTeX超入門   \n",
       "389              講談社        Ｐｙｔｈｏｎで学ぶアルゴリズムとデータ構造   \n",
       "\n",
       "                                      authors  publisher published_date  \\\n",
       "0               Ron Kohavi, Diane Tang, Ya Xu        NaN        2021-03   \n",
       "1                                       澁井 雄介        翔泳社     2021-05-17   \n",
       "2    大城信晃, マスクド・アナライズ, 伊藤徹郎, 小西哲平, 西原成輝, 油井志郎        NaN        2020-12   \n",
       "3                                         NaN        NaN            NaN   \n",
       "4                        佐竹陽一, 山﨑翔平, 小倉大, 峯侑資  SBクリエイティブ     2023-03-31   \n",
       "..                                        ...        ...            ...   \n",
       "385                                      篠田浩一        NaN        2017-12   \n",
       "386                                 青嶋誠, 矢田和善        NaN     2019-04-30   \n",
       "387                                      水谷正大        NaN        2020-07   \n",
       "388                                      水谷正大        NaN        2020-07   \n",
       "389                                 辻真吾, 下平英寿        講談社     2019-11-28   \n",
       "\n",
       "                                           description  page_count categories  \\\n",
       "0               経営層からデータサイエンティスト、エンジニアまで全関係者必読の教科書!...       289.0        NaN   \n",
       "1    機械学習システム構築に必要な デザインパターンがここにある！ 【本書の背景】 Pythonを...       442.0        NaN   \n",
       "2    現場でしか得られないビジネス知識/暗黙知を解説。課題設定→案件獲得→外注見積→契約→分析手法...       320.0        NaN   \n",
       "3                                                  NaN         NaN        NaN   \n",
       "4    現場で役立つ！ AWSトップエンジニアが実践しているシステム運用の手法とコツ ※この電子書籍...       507.0  Computers   \n",
       "..                                                 ...         ...        ...   \n",
       "385  基礎理論はコンパクトにまとめ、「耐雑音」「話者認識」「深層学習」についてたっぷり解説。音声認...       165.0        NaN   \n",
       "386                                                NaN       110.0        NaN   \n",
       "387  理系のレポート作成や論文執筆の定番「LaTeX」の使い方が一冊でわかる!これだけ読めばレポー...       270.0        NaN   \n",
       "388  理系のレポート作成や論文執筆の定番「LaTeX」の使い方が一冊でわかる!これだけ読めばレポー...       270.0        NaN   \n",
       "389  現代社会を支える根幹技術をPythonで！ Pythonプログラミングのスキルアップにも最適...       268.0  Computers   \n",
       "\n",
       "    language                                          thumbnail  use_title  \\\n",
       "0         ja  http://books.google.com/books/content?id=EyRjz...        1.0   \n",
       "1         ja  http://books.google.com/books/content?id=88ArE...        1.0   \n",
       "2         ja  http://books.google.com/books/content?id=s4Idz...        1.0   \n",
       "3        NaN                                                NaN        NaN   \n",
       "4         ja  http://books.google.com/books/content?id=Dnm1E...        1.0   \n",
       "..       ...                                                ...        ...   \n",
       "385       ja  http://books.google.com/books/content?id=tH9ns...        1.0   \n",
       "386       ja  http://books.google.com/books/content?id=ZnI6x...        1.0   \n",
       "387       ja  http://books.google.com/books/content?id=nHWyz...        1.0   \n",
       "388       ja  http://books.google.com/books/content?id=nHWyz...        1.0   \n",
       "389       ja  http://books.google.com/books/content?id=sdnND...        1.0   \n",
       "\n",
       "     use_author  use_publisher  errors  \n",
       "0           1.0            1.0       0  \n",
       "1           1.0            1.0       0  \n",
       "2           1.0            1.0       0  \n",
       "3           NaN            NaN       1  \n",
       "4           0.0            1.0       0  \n",
       "..          ...            ...     ...  \n",
       "385         1.0            1.0       0  \n",
       "386         1.0            1.0       0  \n",
       "387         0.0            1.0       0  \n",
       "388         0.0            1.0       0  \n",
       "389         1.0            1.0       0  \n",
       "\n",
       "[390 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset_20240623_174106.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['経営層からデータサイエンティスト、エンジニアまで全関係者必読の教科書!...',\n",
       " '機械学習システム構築に必要な デザインパターンがここにある！ 【本書の背景】 Pythonを用いた機械学習のモデル開発事例は多数ありますが、 そのモデルをビジネスやシステムに組み込み、運用する事例や方法論は多くありません。 そのため、AIを組み込んだ実装モデルをまとめた、 「機械学習システムのデザインパターン」に注目が集まっています。 【対象読者】 ・AIエンジニア ・システムエンジニア ・機械学習を本番システムとして使うための開発、運用方法で悩んでいるエンジニアの方 【本書の概要】 本書は機械学習を有効活用するためにはシステムに組み込むための設計や 実装が必要と考え、機械学習システムのデザインパターンを集めて解説した書籍です。 機械学習システムのグランドデザインおよびPythonによる機械学習システムの実装例を説明しつつ、 機械学習を本番活用するための方法論や、運用、改善ノウハウについて解説します。 本書で扱うプラットフォームには、コードの再現実行を担保するため、 DockerとKubernetesを活用します。 機械学習の学習から評価、QAを行い、推論器をリリースして 運用するまでの一連の流れをアーキテクチャやコードとともに解説します。 【デザインパターンのサンプル】 本書で解説している実際のサンプルコードをGitHubからダウンロードして利用可能です。 【本書のゴール】 ・機械学習を実用化する方法が学べる ・Pythonによる機械学習ワークフローおよびWebアプリケーション開発の概要を学べる ・機械学習を組み込んだシステムの運用ノウハウを得られる ・機械学習システムのトラブルシューティングや調査方法を学べる 【著者プロフィール】 澁井 雄介（しぶい・ゆうすけ） 株式会社ティアフォー所属。 MLOpsエンジニア、インフラエンジニア、ARエンジニア、ネコ2匹の飼い主。家に猫用ハンモックが4台ある。 本業で自動運転のためのMLOps基盤をKubernetesで開発しつつ、趣味でARとEdge AIを組み合わせて遊んでいる。 過去にはSIer、外資ソフトウェアベンダー、スタートアップで新規プロダクトの起ち上げ、大規模システム運用、チームマネジメントに従事。 前職メルカリにて機械学習をシステムに組み込むデザインパターンを執筆、公開。 ・GitHubで「mercari/ml-system-design-pattern」と検索...',\n",
       " '現場でしか得られないビジネス知識/暗黙知を解説。課題設定→案件獲得→外注見積→契約→分析手法の検討→進行管理→分析結果の評価→レポーティング→分析基盤の構築検討→収益化。プロジェクトの入口から出口までのノウハウを網羅。...',\n",
       " '記述なし',\n",
       " '現場で役立つ！ AWSトップエンジニアが実践しているシステム運用の手法とコツ ※この電子書籍は固定レイアウト型で配信されております。固定レイアウト型は文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 本書では「最初に知っておきたいAWS運用のすべて」を体系立てて解説します。 システム運用で利用するEC2・IAM・RDSといった基本的なサービスはもちろん、 意外と知らないバックアップ/リストア、セキュリティ統制、監査に関わるサービスも基本から丁寧に解説。 日々の運用業務の中で「なるべく楽に」「効率的に」AWSでシステムを運用する手法が満載です。 ■本書の対象読者 ・これからシステム運用に関わる新米エンジニアの方々 ・これまでオンプレミスで運用をしてきたエンジニアのみなさま ■こんな悩みが解消します ・便利なアカウント管理の方法は？ ・最適なログの収集と分析方法は？ ・エラーを管理しやすい監視方法は？ ・ヌケモレを防ぐパッチ適用の方法は？ ・簡単なコスト削減の方法は？ ※カバー画像が異なる場合があります。...',\n",
       " '自然言語処理の標準モデル、BERTを使いこなせるようになる！ BERTはGoogleが2018年末に発表した自然言語処理モデルです。「文脈」を考慮した処理が特徴的であり、言語理解を評価する11個のタスクについて最高精度を達成し、今や標準的なモデルとしての地位を確立しています。 本書は、自然言語処理の近年における発展に大きな役割を果たし、かつ応用上も有用であるBERTの入門書です。前半で自然言語処理や機械学習について概説したのち、BERTによって実際にさまざまなタスクを解いていきます。具体的には、文章分類・固有表現抽出・文章校正・類似文章検索・データの可視化を扱います。データセットの処理から、ファインチューニング（BERTを特定の言語タスクに特化させるための学習）、性能の評価までの一連の流れを体験することで、BERTを自分で使えるようになることを目標とします。 なお、BERTで処理を行うためのライブラリとして、深層学習の言語モデルを扱ううえでよく使用されるTransformersを、学習や性能評価を効率的に行うためのライブラリとしてPyTorch Lightningを用います。本書ではTransformersやPyTorch Lightningを用いたことがない読者を想定して、その使い方を一から体系的かつ丁寧に解説します。 ▼本書の環境 言語：Python 深層学習フレームワーク：PyTorch ライブラリ：Transformers, PyTorch Lightning 計算環境：Google Colaboratory ▼本書の特徴 ・BERTで実際にさまざまなタスクを解くことができます。 ・使用するデータセットを日本語で統一しています。 ・ライブラリの使い方を一から体系的に説明します。 このような方におすすめ ◎自然言語処理を行うエンジニア ◎自然言語処理に興味のある情報系学部などの学生 主要目次 第1章 はじめに 第2章 ニューラルネットワークを用いた自然言語処理 第3章 BERT 第4章 Huggingface Transformers 第5章 文章の穴埋め 第6章 文章分類 第7章 マルチラベル文章分類 第8章 固有表現抽出 第9章 文章校正 第10章 文章ベクトルを用いたデータの可視化と類似文章検索 付録A ニューラルネットワークの学習の基礎 付録B Colaboratoryの使い方...',\n",
       " 'Along with many practical applications, Bayesian Model Selection and Statistical Modeling presents an array of Bayesian inference and model selection procedures. It thoroughly explains the concepts, illustrates the derivations of various Bayesian model selection criteria through examples, and provides R code for implementation. The author shows how to implement a variety of Bayesian inference using R and sampling methods, such as Markov chain Monte Carlo. He covers the different types of simulation-based Bayesian model selection criteria, including the numerical calculation of Bayes factors, the Bayesian predictive information criterion, and the deviance information criterion. He also provides a theoretical basis for the analysis of these criteria. In addition, the author discusses how Bayesian model averaging can simultaneously treat both model and parameter uncertainties. Selecting and constructing the appropriate statistical model significantly affect the quality of results in decision making, forecasting, stochastic structure explorations, and other problems. Helping you choose the right Bayesian model, this book focuses on the framework for Bayesian model selection and includes practical examples of model selection criteria....',\n",
       " '記述なし',\n",
       " \"Bayesian analysis is today understood to be an extremely powerful method of statistical analysis, as well an approach to statistics that is particularly transparent and intuitive. It is thus being extensively and increasingly utilized in virtually every area of science and society that involves analysis of data.A widespread misconception is that Bayesian analysis is a more subjective theory of statistical inference than what is now called classical statistics. This is true neither historically nor in practice. Indeed, objective Bayesian analysis dominated the statistical landscape from roughly 1780 to 1930, long before 'classical' statistics or subjective Bayesian analysis were developed. It has been a subject of intense interest to a multitude of statisticians, mathematicians, philosophers, and scientists. The book, while primarily focusing on the latest and most prominent objective Bayesian methodology, does present much of this fascinating history.The book is written for four different audiences. First, it provides an introduction to objective Bayesian inference for non-statisticians; no previous exposure to Bayesian analysis is needed. Second, the book provides an overview of the development and current state of objective Bayesian analysis and its relationship to other statistical approaches, for those with interest in the philosophy of learning from data. Third, the book presents a careful development of the particular objective Bayesian approach that we recommend, the reference prior approach. Finally, the book presents as much practical objective Bayesian methodology as possible for statisticians and scientists primarily interested in practical applications....\",\n",
       " '記述なし',\n",
       " \"Its main objective is to examine the application and relevance of Bayes' theorem to problems that arise in scientific investigation in which inferences must be made regarding parameter values about which little is known a priori. Begins with a discussion of some important general aspects of the Bayesian approach such as the choice of prior distribution, particularly noninformative prior distribution, the problem of nuisance parameters and the role of sufficient statistics, followed by many standard problems concerned with the comparison of location and scale parameters. The main thrust is an investigation of questions with appropriate analysis of mathematical results which are illustrated with numerical examples, providing evidence of the value of the Bayesian approach....\",\n",
       " '記述なし',\n",
       " 'Bayesian methods combine the evidence from the data at hand with previous quantitative knowledge to analyse practical problems in a wide range of areas. The calculations were previously complex, but it is now possible to routinely apply Bayesian methods due to advances in computing technology and the use of new sampling methods for estimating parameters. Such developments together with the availability of freeware such as WINBUGS and R have facilitated a rapid growth in the use of Bayesian methods, allowing their application in many scientific disciplines, including applied statistics, public health research, medical science, the social sciences and economics. Following the success of the first edition, this reworked and updated book provides an accessible approach to Bayesian computing and analysis, with an emphasis on the principles of prior selection, identification and the interpretation of real data sets. The second edition: Provides an integrated presentation of theory, examples, applications and computer algorithms. Discusses the role of Markov Chain Monte Carlo methods in computing and estimation. Includes a wide range of interdisciplinary applications, and a large selection of worked examples from the health and social sciences. Features a comprehensive range of methodologies and modelling techniques, and examines model fitting in practice using Bayesian principles. Provides exercises designed to help reinforce the reader’s knowledge and a supplementary website containing data sets and relevant programs. Bayesian Statistical Modelling is ideal for researchers in applied statistics, medical science, public health and the social sciences, who will benefit greatly from the examples and applications featured. The book will also appeal to graduate students of applied statistics, data analysis and Bayesian methods, and will provide a great source of reference for both researchers and students. Praise for the First Edition: “It is a remarkable achievement to have carried out such a range of analysis on such a range of data sets. I found this book comprehensive and stimulating, and was thoroughly impressed with both the depth and the range of the discussions it contains.” – ISI - Short Book Reviews “This is an excellent introductory book on Bayesian modelling techniques and data analysis” – Biometrics “The book fills an important niche in the statistical literature and should be a very valuable resource for students and professionals who are utilizing Bayesian methods.” – Journal of Mathematical Psychology...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " 'Buku \"Penerapan Data Mining di Berbagai Bidang: Konsep, Metode, dan Studi Kasus\" membahas tentang penggunaan data mining dalam berbagai bidang, seperti bisnis, industri, Media, pendidikan, dan lain-lain. Buku ini dimulai dengan pengenalan tentang apa itu data mining dan bagaimana penggunaannya dalam berbagai bidang. Selanjutnya, buku ini membahas tentang teknik-teknik data mining yang dapat digunakan, Data Preprocessing, Pembelajaran Mesin untuk Data Mining, Alat dan Perangkat Lunak Data Mining, Data Mining pada Big Data, dan Tren Masa Depan dalam Data Mining. Buku ini juga dilengkapi beberapa studi kasus penggunaan data mining dalam berbagai bidang. Misalnya, Analisis Sentimen dan Pemasaran pada Media Sosial Menggunakan Data Mining, Analisis Data Otomatis Berita Online: Mencari Pola dan Tren pada Topik Tertentu dengan Data Mining, Penerapan Data Mining dalam Meningkatkan Promosi bidang Industri Pariwisata, Penerapan Data Mining pada CRISP-DM, dan Implementasi Data Mining Pada Bidang Pendidikan untuk prediksi Kelulusan Tepat Waktu. Buku \"Penerapan Data Mining di Berbagai Bidang: Konsep, Metode, dan Studi Kasus\" cocok bagi para pemula yang ingin mempelajari konsep dasar data mining dan bagaimana penggunaannya dalam berbagai bidang. Namun, buku ini juga cocok bagi para ahli yang ingin meningkatkan pemahaman mereka tentang data mining dan menerapkannya dalam bidang mereka....',\n",
       " 'This is the first comprehensive book dedicated entirely to the field of decision trees in data mining and covers all aspects of this important technique. Decision trees have become one of the most powerful and popular approaches in knowledge discovery and data mining, the science and technology of exploring large and complex bodies of data in order to discover useful patterns. The area is of great importance because it enables modeling and knowledge extraction from the abundance of data available. Both theoreticians and practitioners are continually seeking techniques to make the process more efficient, cost-effective and accurate. Decision trees, originally implemented in decision theory and statistics, are highly effective tools in other areas such as data mining, text mining, information extraction, machine learning, and pattern recognition. This book invites readers to explore the many benefits in data mining that decision trees offer:: Self-explanatory and easy to follow when compacted; Able to handle a variety of input data: nominal, numeric and textual; Able to process datasets that may have errors or missing values; High predictive performance for a relatively small computational effort; Available in many data mining packages over a variety of platforms; Useful for various tasks, such as classification, regression, clustering and feature selection . Sample Chapter(s). Chapter 1: Introduction to Decision Trees (245 KB). Chapter 6: Advanced Decision Trees (409 KB). Chapter 10: Fuzzy Decision Trees (220 KB). Contents: Introduction to Decision Trees; Growing Decision Trees; Evaluation of Classification Trees; Splitting Criteria; Pruning Trees; Advanced Decision Trees; Decision Forests; Incremental Learning of Decision Trees; Feature Selection; Fuzzy Decision Trees; Hybridization of Decision Trees with Other Techniques; Sequence Classification Using Decision Trees. Readership: Researchers, graduate and undergraduate students in information systems, engineering, computer science, statistics and management....',\n",
       " '記述なし',\n",
       " 'Presents new and up-dated material on both the underlying theory and the practical methodology of directional statistics, helping the reader to utilise and develop the techniques appropriate to their work. The book is divided into three parts. The first part concentrates on statistics on the circle. Topics covered include tests of uniformity, tests of good-of-fit, inference on von Mises distributions and non-parametric methods. The second part considers statistics on spheres of arbitrary dimension, and includes a detailed account of inference on the main distributions on spheres. Recent material on correlation, regression time series, robust techniques, bootstrap methods, density estimation and curve fitting is presented. The third part considers statistics on more general sample spaces, in particular rotation groups, Stiefel manifolds, Grassmann manifolds and complex projective spaces. Shape analysis is considered from the perspective of directional statistics. Written by leading authors in the field, this text will be invaluable not only to researchers in probability and statistics interested in the latest developments in directional statistics, but also to practitioners and researchers in many scientific fields, including astronomy, biology, computer vision, earth sciences and image analysis....',\n",
       " 'EMアルゴリズムについて深く理解できるように、定式化や収束性等の基本的な事項と、その理論的背景についてわかりやすく解説。...',\n",
       " '· Entropy, Relative Entropy and Mutual Information· The Asymptotic Equipartition Property· Entropy Rates of a Stochastic Process· Data Compression· Gambling and Data Compression· Kolmogorov Complexity· Channel Capacity· Differential Entropy· The Gaussian Channel· Maximum Entropy and Spectral Estimation· Information Theory and Statistics· Rate Distortion Theory· Network Information Theory· Information Theory and the Stock Market· Inequalities in Information Theory...',\n",
       " 'An up-to-date, comprehensive account of major issues in finitemixture modeling This volume provides an up-to-date account of the theory andapplications of modeling via finite mixture distributions. With anemphasis on the applications of mixture models in both mainstreamanalysis and other areas such as unsupervised pattern recognition,speech recognition, and medical imaging, the book describes theformulations of the finite mixture approach, details itsmethodology, discusses aspects of its implementation, andillustrates its application in many common statisticalcontexts. Major issues discussed in this book include identifiabilityproblems, actual fitting of finite mixtures through use of the EMalgorithm, properties of the maximum likelihood estimators soobtained, assessment of the number of components to be used in themixture, and the applicability of asymptotic theory in providing abasis for the solutions to some of these problems. The author alsoconsiders how the EM algorithm can be scaled to handle the fittingof mixture models to very large databases, as in data miningapplications. This comprehensive, practical guide: * Provides more than 800 references-40% published since 1995 * Includes an appendix listing available mixture software * Links statistical literature with machine learning and patternrecognition literature * Contains more than 100 helpful graphs, charts, and tables Finite Mixture Models is an important resource for both applied andtheoretical statisticians as well as for researchers in the manyareas in which finite mixture models can be used to analyze data....',\n",
       " 'Missing data pose challenges to real-life data analysis. Simple ad-hoc fixes, like deletion or mean imputation, only work under highly restrictive conditions, which are often not met in practice. Multiple imputation replaces each missing value by multiple plausible values. The variability between these replacements reflects our ignorance of the true (but missing) value. Each of the completed data set is then analyzed by standard methods, and the results are pooled to obtain unbiased estimates with correct confidence intervals. Multiple imputation is a general approach that also inspires novel solutions to old problems by reformulating the task at hand as a missing-data problem. This is the second edition of a popular book on multiple imputation, focused on explaining the application of methods through detailed worked examples using the MICE package as developed by the author. This new edition incorporates the recent developments in this fast-moving field. This class-tested book avoids mathematical and technical details as much as possible: formulas are accompanied by verbal statements that explain the formula in accessible terms. The book sharpens the reader’s intuition on how to think about missing data, and provides all the tools needed to execute a well-grounded quantitative analysis in the presence of missing data....',\n",
       " 'Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications....',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 英文メールを書いていて、「本当にこれでいいのかなあ」と思ったことはありませんか？ 日本語を英訳している際、辞書を引いてもどの単語を使ったらいいのか迷ったことはありませんか？ そんなときは2つの簡単な方法を使ってＧｏｏｇｌｅ検索をしてみましょう。ウェブ上に広がる知識が巨大なデータベースとなり、自分専用の辞書にも、ネイティブ・チェッカーにもなるのです。ライティングに関する悩みを解消する画期的一冊。...',\n",
       " 'An integrated work in two volumes, this text teaches readers to formulate, analyze, and evaluate Markov models. The first volume treats basic process; the second, semi-Markov and decision processes. 1971 edition....',\n",
       " '人と協調する機械学習(Human-in-the-Loop機械学習)の活用で、効率よく高品質なデータを作成していく方法を学ぶ。...',\n",
       " 'Understand key information-theoretic principles that underpin the design of next-generation cellular systems with this invaluable resource. This book is the perfect tool for researchers and graduate students in the field of information theory and wireless communications, as well as for practitioners in the telecommunications industry....',\n",
       " 'Information theory and inference, taught together in this exciting textbook, lie at the heart of many important areas of modern technology - communication, signal processing, data mining, machine learning, pattern recognition, computational neuroscience, bioinformatics and cryptography. The book introduces theory in tandem with applications. Information theory is taught alongside practical communication systems such as arithmetic coding for data compression and sparse-graph codes for error-correction. Inference techniques, including message-passing algorithms, Monte Carlo methods and variational approximations, are developed alongside applications to clustering, convolutional codes, independent component analysis, and neural networks. Uniquely, the book covers state-of-the-art error-correcting codes, including low-density-parity-check codes, turbo codes, and digital fountain codes - the twenty-first-century standards for satellite communications, disk drives, and data broadcast. Richly illustrated, filled with worked examples and over 400 exercises, some with detailed solutions, the book is ideal for self-learning, and for undergraduate or graduate courses. It also provides an unparalleled entry point for professionals in areas as diverse as computational biology, financial engineering and machine learning....',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '●Kaggleは楽しい! Kaggleは誰でも気軽に参加できるデータ分析の競技コンペです。 コンペで試した技を、実務に応用する――そのシナジーにより、みるみる実力が付きます。 Kaggleマスターの著者自身がそうして得たノウハウを、惜しげもなく本書では公開します。 しかし、本書を通じてお伝えしたいのは、何よりKaggleのワクワク感です!...',\n",
       " 'LightGBMを使った予測モデルの解説書です。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " 'Given a data set, you can fit thousands of models at the push of a button, but how do you choose the best? With so many candidate models, overfitting is a real danger. Is the monkey who typed Hamlet actually a good writer? Choosing a model is central to all statistical work with data. We have seen rapid advances in model fitting and in the theoretical understanding of model selection, yet this book is the first to synthesize research and practice from this active field. Model choice criteria are explained, discussed and compared, including the AIC, BIC, DIC and FIC. The uncertainties involved with model selection are tackled, with discussions of frequentist and Bayesian methods; model averaging schemes are presented. Real-data examples are complemented by derivations providing deeper insight into the methodology, and instructive exercises build familiarity with the methods. The companion website features Data sets and R code....',\n",
       " 'Decision functions. Pattern classification by distance functions. Pattern classification by likelihood functions. Trainable pattern classifiers-the deterministic approach. Trainable pattern classifiers - the statistical approach. Pattern preprocessing and feature selection. Syntatic pattern recognition. Bibliography. Index....',\n",
       " 'Advances in hardware technology have increased the capability to store and record personal data. This has caused concerns that personal data may be abused. This book proposes a number of techniques to perform the data mining tasks in a privacy-preserving way. This edited volume contains surveys by distinguished researchers in the privacy field. Each survey includes the key research content as well as future research directions of a particular topic in privacy. The book is designed for researchers, professors, and advanced-level students in computer science, but is also suitable for practitioners in industry....',\n",
       " 'Like the previous editions, this new edition will be well received by students of mathematics, statistics, economics, and a wide variety of disciplines that require a solid understanding of probability theory....',\n",
       " 'Distills key concepts from linear algebra, geometry, matrices, calculus, optimization, probability and statistics that are used in machine learning....',\n",
       " '第3版まで続くロングセラーのPyTorch版！ 機械学習の基本から先進的な手法まで本格解説 『機械学習を実践的に学ぶための優れたテキスト』 『多くのトピックを網羅した深い一冊。強力にお勧め』 ―原著への読者の声 本書の前半は、基本的な機械学習ライブラリのscikit-learnを使った手法を解説。 分類の基本モデルに始まり、単層ニューラルネットまでを実装するほか、データ前処理、次元削減、 ハイパーパラメーターのチューニング、アンサンブル学習、回帰分析などを取り上げます。 後半では、PyTorchによるさまざまなディープラーニングの手法を説明。 PyTorchの仕組みを示したあと、CNN／RNN／Transformerといったモデルの実装を解説。 敵対的生成ネットワーク、グラフニューラルネットワーク、強化学習もカバー。 ◎本書は『Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python』の翻訳書です。 ◎微積分/線形代数、Pythonの文法、データ分析用ライブラリについてある程度理解している必要があります。 発行：インプレス...',\n",
       " '会計データを用いた機械学習、売上予測、異常検知、在庫予測、貸倒予測等の実践方法を詳解。...',\n",
       " '初学者向けのKaggle入門書の決定版! サンプルコードの詳細解説でしっかり身につく。「Kaggleで勝つ」準備をしよう!...',\n",
       " '★確率的プログラミング言語がすぐに使える！★ ・Pythonでのコーディングを前提に、PyMC3、Pyro、NumPyro、TFP、GPyTorchをカバー。 ・回帰モデルの基本から潜在変数モデル・深層学習モデルまでを幅広く解説。 【主な内容】 第1章 ベイジアンモデリングとは 1.1 データ解析とコンピュータ 1.2 ベイジアンモデリングの基礎 1.3 代表的な確率分布 1.4 近似推論手法 第2章 確率的プログラミング言語（PPL） 2.1 ベイジアンモデリングとPPL 2.2 自動微分・最適化アルゴリズム 2.3 PyMC3の概要 2.4 Pyroの概要 2.5 NumPyroの概要 2.6 TensorFlow Probabilityの概要 2.7 GPyTorchの概要 第3章 回帰モデル 3.1 線形回帰モデル：線形単回帰モデル 3.2 線形回帰モデル：線形重回帰モデル 3.3 一般化線形モデル：ポアソン回帰モデル 3.4 一般化線形モデル：ロジスティック回帰モデル 3.5 階層ベイズモデル 3.6 ガウス過程回帰モデル：ガウス尤度 3.7 ガウス過程回帰モデル：尤度の一般化 第4章 潜在変数モデル 4.1 混合ガウスモデル 4.2 行列分解モデル 4.3 状態空間モデル 4.4 隠れマルコフモデル 4.5 トピックモデル 4.6 ガウス過程潜在変数モデル 第5章 深層学習モデル 5.1 ニューラルネットワーク回帰モデル 5.2 変分自己符号化器 5.3 PixelCNN 5.4 深層ガウス過程 5.5 正規化流...',\n",
       " 'Pythonで実務に使える数理最適化のスキルを身につけよう！ ▼この本の特徴 本書は、Pythonを用いた数理最適化の入門書です。Pythonを使ってさまざまな課題を実際に解いてみることで、数理モデルを実務で使いこなす力を身につけます。 この本の特徴は、数理最適化のアルゴリズム自体ではなく、数理最適化を用いた課題解決に重きを置いている点です。ビジネスなどにおける課題を数理最適化で解く際に現場で発生しうる試行錯誤が多分に盛り込まれており、実務における手順や気をつけるべきポイントを学習することができます。 ▼この本の構成 本書は二部構成です。 第Ⅰ部はチュートリアルです。中学校で習う連立一次方程式や高校で習う線形計画法を題材として、数理最適化の基礎的な考え方とPythonによる初歩的な実装を学びます。シンプルな課題設定なので、数学的な難しさを感じることなくPythonに集中して基礎を学習することができます。 第Ⅱ部はケーススタディです。 実際に社会で起こりうる、さまざまな課題を数理最適化によって解いていきます。 学校のクラス編成やサークル活動における学生の乗車グループ分けなどの学生にとっても身近な課題や、キャンペーンの効果最大化や効率のよい配送計画の立案などのビジネスにおいてたびたびぶつかる課題などを解いていくことで、手順や注意点、効率のよい方法などが学べます。 ▼第1版からの変更箇所 ・5章（車両の配送計画） 問題の理解を助けるために挿絵・最適化結果の可視化を増やし、実装プログラムの解説を充実させました。また、最適化に登場する部品の列挙アルゴリズムについては、計算速度よりも理解しやすさを優先したものに差し替えました。 ・6章（数理最適化APIとWebアプリケーションの開発）にFastAPIやStreamlitの記述を追加 PythonのWebアプリケーション開発のフレームワークであるFlaskに加え、人気のFastAPIやデータサイエンティストでも簡単にWebアプリケーションが開発できるStreamlitについて追記しました。 ・7章（商品推薦のための興味のスコアリング）行列表現に関する説明の調整 簡単な数理最適化問題の行列表現から解説を行い、段階を踏んで理解できるようにしました。さらに、ソースコードの解説を追記することで、プログラムにおける行列の扱い方を理解しやすくなりました。 ▼このような方におすすめ ◎ 数理最適化の実務応用について知りたい方 ◎ 施策の効果最大化や効率化に取り組むビジネスマン（エンジニア・マーケター・リサーチャーなど） ◎ 情報・経済・経営系などの学部や学科の学生 ◎ データサイエンティストを志す方 このような方におすすめ ◎ 数理最適化の実務応用について知りたい方 ◎ 施策の効果最大化や効率化に取り組むビジネスマン（エンジニア・マーケター・リサーチャーなど） ◎ 情報・経済・経営系などの学部や学科の学生 ◎ データサイエンティストを志す方 主要目次 第Ⅰ部 数理最適化チュートリアル 第1章 数理モデルとは 第2章 Python数理最適化チュートリアル 第Ⅱ部 数理最適化のケーススタディ 第3章 学校のクラス編成 第4章 割引クーポンキャンペーンの効果最大化 第5章 最小コストで行う輸送車両の配送計画 第6章 数理最適化APIとWebアプリケーションの開発 第7章 商品推薦のための興味のスコアリング Appendix メソッド・関数早見表...',\n",
       " '★数学とプログラミングを対比させながら、一歩一歩わかりやすく！ 実務に即してPyMC5プログラミングでベイズ推論を使いこなせるようになる。 最初の一冊として、データサイエンティストにおすすめ！ 【サポートサイト】 https://github.com/makaishi2/python_bayes_intro 【主な内容】 第1章 確率分布を理解する 1.1 ベイズ推論における確率分布の必要性 1.2 確率変数と確率分布 1.3 離散分布と連続分布 1.4 PyMCによる確率モデル定義とサンプリング 1.5 サンプリング結果分析 1.6 確率分布とPyMCプログラミングの関係 第2章 よく利用される確率分布 2.1 ベルヌーイ分布（pm.Bernoulliクラス） 2.2 二項分布（pm.Binomial クラス） 2.3 正規分布（pm.Normal クラス） 2.4 一様分布（pm.Uniform クラス） 2.5 ベータ分布（pm.Beta クラス） 2.6 半正規分布（pm.HalfNormal クラス） 第3章 ベイズ推論とは 3.1 ベイズ推論利用の目的 3.2 問題設定 3.3 最尤推定による解法 3.4 ベイズ推論による解法 3.5 ベイズ推論の精度を上げる方法 3.6 ベイズ推論の活用例 第4章 はじめてのベイズ推論実習 4.1 問題設定 (再掲) 4.2 最尤推定 4.3 ベイズ推論 (確率モデル定義） 4.4 ベイズ推論 (サンプリング） 4.5 ベイズ推論 (結果分析） 4.6 ベイズ推論 (二項分布バージョン） 4.7 ベイズ推論 (試行回数を増やす） 4.8 ベイズ推論 (事前分布の変更） 4.9 ベータ分布で直接確率分布を求める 第5章 ベイズ推論プログラミング 5.1 データ分布のベイズ推論 5.2 線形回帰のベイズ推論 5.3 階層ベイズモデル 5.4 潜在変数モデル 第6章 ベイズ推論の業務活用事例 6.1 ABテストの効果検証 6.2 ベイズ回帰モデルによる効果検証 6.3 IRT (Item Response Theory）によるテスト結果評価...',\n",
       " '機械学習エンジニア必見！ ベイズ統計の基礎から ベイズ統計モデリングまで Pythonプログラムをもとに丁寧に解説！ 【本書の内容】 ベイズ統計の基礎知識からベイズ統計モデリングまで、 Pythonのプログラムをもとにわかりやすく解説した書籍です。 前半ではベイズ統計の理解に必要な確率の説明からはじまり、 ベイズ統計学、ベイズの定理、ベイズ推定の基本事項をわかりやすく解説。 後半では線形モデルを例題として、MCMC法を用いたモデルの推定方法について解説します。 【本書で扱うベイズの定理について】 事後分布を求める際に問題となる、ベイズの定理の積分計算を回避する方法を2つ紹介します。 1つは、共役事前分布によって事後分布の解析解を求める方法です。 そしてもう1つは、MCMC法を使用することで数値計算によって事後分布を推定する方法です。 MCMC法はPythonのライブラリのPyMC3を用いて手軽に実践することができます。 【本書の扱うベイズ統計の範囲】 ・確率の基本 ・ベイズの定理 ・ベイズ推定 ・MCMC法：マルコフ連鎖モンテカルロ法 ・線形モデル ・一般化線形モデル 【対象読者】 ・ベイズ統計モデリングをこれから学ぼうとされる方 ・ベイズ統計モデリングの基礎知識が少ない機械学習エンジニア 【著者プロフィール】 かくあき 学生時代から数値解析を中心にPython,Matlab,Fortran,C,LISPなどのプログラミング言語を利用している。 Pythonの普及の一助となるべく、Udemyで講座を公開。 Kindle Direct Publishingで電子書籍を出版するなど、情報発信を行う。 著書に『現場で使える！Python科学技術計算入門』（翔泳社）がある。...',\n",
       " 'AI開発に必要な数学の基礎知識がこれ1冊でわかる! 【本書の目的】 本書は以下のような対象読者に向けて、 線形代数、確率、統計/微分 といった数学の基礎知識をわかりやすく解説した書籍です。 【対象読者】 • 数学がAIや機械学習を勉強する際の障壁になっている方 • AIをビジネスで扱う必要に迫られた方 • 数学を改めて学び直したい方 • 文系の方、非エンジニアの方で数学の知識に自信のない方 • コードを書きながら数学を学びたい方 【目次】 序章 イントロダクション 第1章 学習の準備をしよう 第2章 Pythonの基礎 第3章 数学の基礎 第4章 線形代数 第5章 微分 第6章 確率・統計 第7章 数学を機械学習で実践 Appendix さらに学びたい方のために ※本電子書籍は同名出版物を底本として作成しました。記載内容は印刷出版当時のものです。 ※印刷出版再現のため電子書籍としては不要な情報を含んでいる場合があります。 ※印刷出版とは異なる表記・表現の場合があります。予めご了承ください。 ※プレビューにてお手持ちの電子端末での表示状態をご確認の上、商品をお買い求めください。 (翔泳社)...',\n",
       " '★ 実験を効率化する強い味方 ★ もう実験で疲弊しない。次に試す実験条件は、データと統計学が教えてくれる！ ベイズ最適化とPythonを駆使して、効率よく研究・開発を進めよう！ 《すぐに試せるサンプルデータセット・サンプルコード付き》 ■ データ解析の初歩から、モデルの設計、実践的な応用事例までを導く。 ■ 実験時間や人数が限られる今、絶対に役立つスキルが身につく！ ■ 入門書であり、実践書。フルカラー！ 【目次】 第1章 データ解析や機械学習を活用した分子設計・材料設計・プロセス設計・プロセス管理 ・ケモ・マテリアルズ・プロセスインフォマティクス ・分子設計 ・材料設計 ・なぜベイズ最適化が必要か ・プロセス設計 ・プロセス管理 ・データ解析・人工知能（モデル）の本質 第2章 実験計画法 ・なぜ実験計画法か ・実験計画法とは ・適応的実験計画法 ・必要となる手法・技術 第3章 データ解析や回帰分析の手法 ・データセットの表現 ・ヒストグラム・散布図の確認 ・統計量の確認 ・特徴量の標準化 ・最小二乗法による線形重回帰分析 ・回帰モデルの推定性能の評価 ・非線形重回帰分析 ・決定木 ・ランダムフォレスト ・サポートベクター回帰 ・ガウス過程回帰 第4章 モデルの適用範囲 ・モデルの適用範囲とは ・データ密度 ・アンサンブル学習 第5章 実験計画法・適応的実験計画法の実践 ・実験候補の生成 ・実験候補の選択 ・次の実験候補の選択 ・ベイズ最適化 ・化学構造を扱うときはどうするか 第6章 応用事例 ・複雑な非線形関数を用いた実験計画法・適応的実験計画法の実践 ・分子設計 ・材料設計 ・プロセス設計 第7章 さらなる深みを目指すために ・Gaussian Mixture Regression（GMR） ・GMR-Based Optimization（GMRBO）（GMRに基づく適応的実験計画法） ・複雑な非線形関数を用いたGMRBOの検証 第8章 数学の基礎・Anaconda・Spyder ・行列やベクトルの表現・転置行列・逆行列・固有値分解 ・最尤推定法・正規分布 ・確率・同時確率・条件付き確率・確率の乗法定理 ・AnacondaとRDKitのインストール・Spyderの使い方...',\n",
       " 'Pythonのライブラリを使ってデータ分析...',\n",
       " '時系列データを上手く活用し、ビジネス成果を生み出す!! 時系列データを上手く調理することは、これらの問に何かしら解を与えることができます。特に予測モデルを上手く活用すると、過去を振り返り、未来を予測し、現在すべきことを導きだし、成果へと繋げることができます。いくら高精度な予測モデルを手にしても、どう活用すべきかわからないと成果は生まれません。そこで本書ではどのように扱うかを、実際のデータを用いて、使い方を重点的に解説していきます。時系列分析の多くの書籍は数式等を用いて解説していますが、実務的な運用には理論よりもPython等コードで実践していくことが重要です。 なお、事例として以下を取り上げます。 ・モニタリング指標の異常検知によるキャンペーン評価（自動車ディーラー） ・モニタリング指標の異常検知と要因探索（小売りチェーン） ・売上予測モデルを活用したデータドリブン販促（小売りチェーン） ・離反予測モデルによる離反対策ルールの策定（食品・法人向けビジネス） ・チャーンマネジメントのための離反時期予測（携帯電話サービス） ・LTVマネジメントのためのLTV予測（ECサイト） ・広告・販促効果を見える化し最適化するマーケティング・ミックス・モデリング（スポーツジム） このような方におすすめ ・機械学習エンジニア ・時系列分析を扱うデータサイエンティスト、マーケター、データアナリストなど。 主要目次 第1章 ビジネスにおける時系列データ活用 第2章 Pythonのデータ分析環境の設定（JupyterLab） 第3章 時系列予測モデル構築・超入門 第4章 時系列データを使ったビジネス成果の上げ方 第5章 時系列データを活用したビジネス事例...',\n",
       " 'Pythonによるデータ分析について、データの整理や統計的分析、機械学習~因果推論まで網羅。“困ったときの逆引き事典”も掲載。...',\n",
       " '記述なし',\n",
       " 'This second edition of a well-received text, with 20 new chapters, presents a coherent and unified repository of recommender systems’ major concepts, theories, methodologies, trends, and challenges. A variety of real-world applications and detailed case studies are included. In addition to wholesale revision of the existing chapters, this edition includes new topics including: decision making and recommender systems, reciprocal recommender systems, recommender systems in social networks, mobile recommender systems, explanations for recommender systems, music recommender systems, cross-domain recommendations, privacy in recommender systems, and semantic-based recommender systems. This multi-disciplinary handbook involves world-wide experts from diverse fields such as artificial intelligence, human-computer interaction, information retrieval, data mining, mathematics, statistics, adaptive user interfaces, decision support systems, psychology, marketing, and consumer behavior. Theoreticians and practitioners from these fields will find this reference to be an invaluable source of ideas, methods and techniques for developing more efficient, cost-effective and accurate recommender systems....',\n",
       " 'R(統計計算などに使われるフリーソフト)を使ったクラスタリング手法を解説する。クラスタリングとは検索結果の文脈やキーワードにより、類似性を持つ一つのまとまり(クラスタ)にまとめ、自動的に分類する技術。本書ではクラスタリング手法を R で実行して見せる。またその中で、Rの利用方法や、Rによるプログラミングを同時に学ぶことができる。...',\n",
       " '記述なし',\n",
       " 'ベイズ統計の基礎、マルコフ連鎖モンテカルロ法、推論と予測、モデル構築、統計グラフィックス...ベイズ統計学の基礎知識と実践的技法を学ぶテキスト。...',\n",
       " '★まずは実行しよう。数理はそれからだ。★ 初学者が無理なく読み進められるように、ていねいに解説した。まずは、Rでデータ解析を実践し、Rの操作を習熟したら、数理的側面を学ぶ構成。理解の定着に役立つ練習問題が充実！ コードはWebで公開。 【サポートページ】 https://sites.google.com/view/ihsayah/sdar 【主な内容】 第1章 準備：Rの操作 第2章 データの可視化と要約 第3章 回帰分析（1）：単回帰モデル・重回帰モデル 第4章 回帰分析（2）：統計的推測・正則化法に基づく回帰分析 第5章 判別分析 第6章 ロジスティック回帰モデル 第7章 単純な規則に基づく判別モデル：決定木・インデックスモデル 第8章 主成分分析 第9章 クラスター分析 第10章 ブートストラップ法 第11章 Rを用いたシミュレーション：数理統計学を「実感」する 【「巻頭言」より抜粋】 文部科学省は「数理及びデータサイエンスに係る教育強化拠点」6 大学(北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学)を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。 本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。 データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 ――編集委員長 竹村彰通(滋賀大学データサイエンス学部学部長、教授)...',\n",
       " '実務の課題をRを使いながら実践的に解決...',\n",
       " 'データの統計分析、モデル構築、応用を解説...',\n",
       " '空間データの分析手法をRを用いながら解説...',\n",
       " 'データ科学に必要な確率と統計の基本的な考え方を具体例を中心に据えRを用いながら学ぶ教科書...',\n",
       " '経済学・経営学を学ぶ学部学生向けテキスト...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " 'Statistical pattern recognition relates to the use of statistical techniques for analysing data measurements in order to extract information and make justified decisions. It is a very active area of study and research, which has seen many advances in recent years. Applications such as data mining, web searching, multimedia data retrieval, face recognition, and cursive handwriting recognition, all require robust and efficient pattern recognition techniques. This third edition provides an introduction to statistical pattern theory and techniques, with material drawn from a wide range of fields, including the areas of engineering, statistics, computer science and the social sciences. The book has been updated to cover new methods and applications, and includes a wide range of techniques such as Bayesian methods, neural networks, support vector machines, feature selection and feature reduction techniques.Technical descriptions and motivations are provided, and the techniques are illustrated using real examples. Statistical Pattern Recognition, 3rd Edition: Provides a self-contained introduction to statistical pattern recognition. Includes new material presenting the analysis of complex networks. Introduces readers to methods for Bayesian density estimation. Presents descriptions of new applications in biometrics, security, finance and condition monitoring. Provides descriptions and guidance for implementing techniques, which will be invaluable to software engineers and developers seeking to develop real applications Describes mathematically the range of statistical pattern recognition techniques. Presents a variety of exercises including more extensive computer projects. The in-depth technical descriptions make the book suitable for senior undergraduate and graduate students in statistics, computer science and engineering. Statistical Pattern Recognition is also an excellent reference source for technical professionals. Chapters have been arranged to facilitate implementation of the techniques by software engineers and developers in non-statistical engineering fields. www.wiley.com/go/statistical_pattern_recognition...',\n",
       " \"The second edition of a bestseller, Statistical and Machine-Learning Data Mining: Techniques for Better Predictive Modeling and Analysis of Big Data is still the only book, to date, to distinguish between statistical data mining and machine-learning data mining. The first edition, titled Statistical Modeling and Analysis for Database Marketing: Effective Techniques for Mining Big Data, contained 17 chapters of innovative and practical statistical data mining techniques. In this second edition, renamed to reflect the increased coverage of machine-learning data mining techniques, the author has completely revised, reorganized, and repositioned the original chapters and produced 14 new chapters of creative and useful machine-learning data mining techniques. In sum, the 31 chapters of simple yet insightful quantitative techniques make this book unique in the field of data mining literature. The statistical data mining methods effectively consider big data for identifying structures (variables) with the appropriate predictive power in order to yield reliable and robust large-scale statistical models and analyses. In contrast, the author's own GenIQ Model provides machine-learning solutions to common and virtually unapproachable statistical problems. GenIQ makes this possible — its utilitarian data mining features start where statistical data mining stops. This book contains essays offering detailed background, discussion, and illustration of specific methods for solving the most commonly experienced problems in predictive modeling and analysis of big data. They address each methodology and assign its application to a specific type of problem. To better ground readers, the book provides an in-depth discussion of the basic methodologies of predictive modeling and analysis. While this type of overview has been attempted before, this approach offers a truly nitty-gritty, step-by-step method that both tyros and experts in the field can enjoy playing with....\",\n",
       " 'This book provides a perspective on the application of machine learning-based methods in knowledge discovery from natural languages texts. By analysing various data sets, conclusions which are not normally evident, emerge and can be used for various purposes and applications. The book provides explanations of principles of time-proven machine learning algorithms applied in text mining together with step-by-step demonstrations of how to reveal the semantic contents in real-world datasets using the popular R-language with its implemented machine learning algorithms. The book is not only aimed at IT specialists, but is meant for a wider audience that needs to process big sets of text documents and has basic knowledge of the subject, e.g. e-mail service providers, online shoppers, librarians, etc. The book starts with an introduction to text-based natural language data processing and its goals and problems. It focuses on machine learning, presenting various algorithms with their use and possibilities, and reviews the positives and negatives. Beginning with the initial data pre-processing, a reader can follow the steps provided in the R-language including the subsuming of various available plug-ins into the resulting software tool. A big advantage is that R also contains many libraries implementing machine learning algorithms, so a reader can concentrate on the principal target without the need to implement the details of the algorithms her- or himself. To make sense of the results, the book also provides explanations of the algorithms, which supports the final evaluation and interpretation of the results. The examples are demonstrated using realworld data from commonly accessible Internet sources....',\n",
       " \"The only single-source——now completely updated and revised——to offer a unified treatment of the theory, methodology, and applications of the EM algorithm Complete with updates that capture developments from the past decade, The EM Algorithm and Extensions, Second Edition successfully provides a basic understanding of the EM algorithm by describing its inception, implementation, and applicability in numerous statistical contexts. In conjunction with the fundamentals of the topic, the authors discuss convergence issues and computation of standard errors, and, in addition, unveil many parallels and connections between the EM algorithm and Markov chain Monte Carlo algorithms. Thorough discussions on the complexities and drawbacks that arise from the basic EM algorithm, such as slow convergence and lack of an in-built procedure to compute the covariance matrix of parameter estimates, are also presented. While the general philosophy of the First Edition has been maintained, this timely new edition has been updated, revised, and expanded to include: New chapters on Monte Carlo versions of the EM algorithm and generalizations of the EM algorithm New results on convergence, including convergence of the EM algorithm in constrained parameter spaces Expanded discussion of standard error computation methods, such as methods for categorical data and methods based on numerical differentiation Coverage of the interval EM, which locates all stationary points in a designated region of the parameter space Exploration of the EM algorithm's relationship with the Gibbs sampler and other Markov chain Monte Carlo methods Plentiful pedagogical elements—chapter introductions, lists of examples, author and subject indices, computer-drawn graphics, and a related Web site The EM Algorithm and Extensions, Second Edition serves as an excellent text for graduate-level statistics students and is also a comprehensive resource for theoreticians, practitioners, and researchers in the social and physical sciences who would like to extend their knowledge of the EM algorithm....\",\n",
       " 'During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book’s coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression & path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for “wide” data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting....',\n",
       " '自然言語処理分野におけるブレイクスルーとなったTransformerをコンピュータビジョンに応用したモデルがVision Transformer(ViT)です。さまざまなコンピュータビジョンのタスクにおいて、ディープラーニングではスタンダードとなっているRNN、CNN、および既存手法を用いた処理精度を上回ることが確認されています。 本書は注目のViTの入門書です。Transformerの成り立ちからはじめ、その理論と実装を解説していきます。今後のViTの活用が期待される応用タスク、ViTから派生したモデルを紹介したあと、TransoformerとViTを分析し、その謎を解明していきます。今後も普及が期待されるViTを盛りだくさんでお届けします。 目次 1章 TransformerからVision Transformerへの進化 2章 Vision Transformerの基礎と実装 3章実験と可視化によるVision Transformerの探求 4章コンピュータビジョンへの応用 5章 Vision and Languageへの応用 6章 Vision Transformerの派生手法 7章 Transformerの謎を読み解く 8章 Vision Transformerの謎を読み解く...',\n",
       " 'Web戦略対応への実践科学的示唆を提示...',\n",
       " '◆AIの説明責任を果たす ◆ ◆◆手法とツールを解説◆◆ AIが出した答について「なぜ?」「どうして、そうなるの?」と問われた開発者は、絶句するほかありません。そこを機械に任せるための機械学習なのですから、「黙って信じてください」と頼みますか? この難問に対し、人間が納得できそうな理由や根拠を示す技術が「説明可能なAI」(eXplainable AI:XAI)です。本書では、実際にどのような「説明」が必要とされ、また、可能なのかを丁寧に解説。代表的なXAI技術の概要を紹介し、PythonのXAIライブラリLIMEやSHAP等の使いこなしを手引き。AIの業務適用で迫られる「公平性・説明責任・透明性」という3 つの要求に備えます。...',\n",
       " '機械学習の考え方とPython実装法がわかる! 分類/回帰問題や深層学習の導入を解説。 ◎絶妙なバランスで「理論と実践」を展開 ◎Pythonライブラリを使いこなす ◎数式・図・Pythonコードを理解する 本書は、機械学習の理論とPython実践法を網羅的に解説した技術書です。機械学習とは、データから学習した結果をもとに判定や予測を行うことです。すでにさまざまな機械学習の方法が開発されています。本書では、それらの方法について背景にある理論や特徴を解説した上で、Pythonによる実装法を説明します。初期の機械学習アルゴリズムから取り上げ、前処理や次元削減、Webへの展開のほか、終盤ではディープラーニングについても見ていきます。機械学習の理論と実践についてバランスよく解説してあり、AIプログラミングの第一歩を踏み出すための格好の一冊です。 ※本書は『Python Machine Learning』の翻訳書です。 ※付録では、本書を読み進めるにあたっての前提知識として、Python ライブラリや数学について補足説明をしています。必要に応じて、他の書籍などもご参照ください。 発行：インプレス...',\n",
       " '第3版まで続くロングセラーのPyTorch版！ 機械学習の基本から先進的な手法まで本格解説 『機械学習を実践的に学ぶための優れたテキスト』 『多くのトピックを網羅した深い一冊。強力にお勧め』 ―原著への読者の声 本書の前半は、基本的な機械学習ライブラリのscikit-learnを使った手法を解説。 分類の基本モデルに始まり、単層ニューラルネットまでを実装するほか、データ前処理、次元削減、 ハイパーパラメーターのチューニング、アンサンブル学習、回帰分析などを取り上げます。 後半では、PyTorchによるさまざまなディープラーニングの手法を説明。 PyTorchの仕組みを示したあと、CNN／RNN／Transformerといったモデルの実装を解説。 敵対的生成ネットワーク、グラフニューラルネットワーク、強化学習もカバー。 ◎本書は『Machine Learning with PyTorch and Scikit-Learn: Develop machine learning and deep learning models with Python』の翻訳書です。 ◎微積分/線形代数、Pythonの文法、データ分析用ライブラリについてある程度理解している必要があります。 発行：インプレス...',\n",
       " '最新のPythonを深く理解し、使いこなすために必要な基礎を伝授!プログラミング言語としてのPythonの文法や、組み込みのオブジェクトに焦点を絞って解説。入門書やチュートリアルではあまり触られない、Pythonの内部や仕組みに関するトピックも盛り込んだ。...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 ★ビジュアルプログラミングからオブジェクト指向プログラミングへ。さあ、はじめよう！★ MicroPython ver2.0に対応した改訂版。LEGO MINDSTORMS EV3を用いるロボットプログラミングもPythonで自由自在！ ソースコードの解説が丁寧だから大丈夫。プログラムを書いて、すぐロボットが動くからSTEM教育の導入としても最適。センサ、機構、ライントレース、Open Roberta Labなどの発展的な話題も豊富。 いま、テキストベースのプログラミング言語Pythonが注目されています。人工知能(AI)を応用したアプリケーション開発やビッグデータ解析、ロボットアプリケーション開発などの分野でよく使用されており、さらに初心者のプログラミング学習にも向いています。したがって、Pythonを学ぶことは、ロボットプログラミングを始めたい人にとって大いに意味があります。 本書では、EV3ソフトウェアとPythonでプログラムを書きます。2つのプログラムの対応がよくわかるように、EV3ソフトウェアのプログラムを説明した後に、Python のプログラムを説明します。Pythonのプログラムの説明では、EV3ソフトウェアのプログラム中のブロックに相当する手続きがどこで使われているかについても説明します。 【主な内容】 1章 はじめに 2章 プログラミングの準備をしよう 3章 ロボットプログラミングをはじめよう 4章 ロボットを動かしてみよう （基本プログラム/ ステータスライトを光らせる/ 音を鳴らす/ ディスプレイに文字を描画する/ モーターを回転させる） 5章 センサーを使って動かそう （EV3 で使用できるセンサー/ タッチセンサーを使おう/ カラーセンサーを使おう/ ジャイロセンサーを使おう/ 超音波センサーを使おう/ モーター回転センサーを使おう） 6章 オリジナルロボットを作ろう （ロボット製作のための力学・機構/ 力学・機構のための数学的準備/ 力学の基礎/ 基本的な機構/ 車輪移動機構/ ロボットアームとエンドエフェクター） 7章 実践してみよう （ボタンを押してすぐに実行する/ 複雑な動作をプログラミングするためのテクニック/ ライントレース/ 線の検出） 8章 Open Roberta Lab （Open Roberta Labとは/ 画面の説明/ プログラミング/ 保存と読み込み/ シミュレーター/ ロボットの設定/Open Roberta Lab からEV3 を動かす） 付録A リファレンス ※この商品は紙の書籍のページを画像にした電子書籍です。文字だけを拡大することはできませんので、タブレットサイズの端末での閲読を推奨します。また、文字列のハイライトや検索、辞書の参照、引用などの機能も使用できません。...',\n",
       " '【道具として使いこなす！】 膨大な観測データから普遍的な法則を抽出する手法とは？ 高校数学レベルから始まり、Python入門、TensorFlowによる実装、最新の論文まで踏み込む入門書。 【著者サポートページ】 https://github.com/akio-tomiya/intro_ml_in_physics 【目次】 第1章 データとサイエンス 1.1 物理学とデータサイエンス／1.2 最小2乗法とオーバーフィット／1.3 テイラー展開と振り子の等時性／コラム：武谷の三段階論 第2章 行列と線形変換 2.1 ベクトル、行列と線形変換／2.2 変換としての行列／2.3 行列に関する色々／コラム：計算量のオーダー 第3章 確率論と機械学習 3.1 確率の基礎事項／3.2 教師あり学習と教師なし学習、強化学習／3.3 確率変数と経験的確率、大数の法則／3.4 大数の弱法則の証明／3.5 カルバックライブラーダイバージェンス／3.6 尤度と赤池情報量基準、汎化／3.7 ロジスティック回帰 第4章 ニューラルネットワーク 4.1 ニューラルネットワークの概論／4.2 万能近似定理／コラム：新しい道具と新理論 第5章 トレーニングとデータ 5.1 ニューラルネットワークの入出力と学習／5.2 誤差関数と汎化、過学習／5.3 誤差関数の最適化・学習／コラム：次元の呪い 第6章 Python入門 6.1 Pythonによるプログラミング入門／6.2 Pythonと他言語の比較／6.3 NumPyとMatplotlib／6.4 Pythonでのクラス 第7章 TensorFlowによる実装 7.1 TensorFlow/Kerasとは／7.2 データやライブラリのロード／7.3 データの分割とニューラルネットワークの設計／7.4 学習／7.5 結果の評価／コラム：量子化という用語 第8章 最適化、正則化、深層化 8.1 最適化法の改良／8.2 過学習を防ぐ／8.3 多層化にむけて 第9章 畳み込みニューラルネットワーク 9.1 フィルター／9.2 畳み込みニューラルネット／コラム：知能と飛行機 第10章 イジング模型の統計力学 10.1 イジング模型／10.2 イジング模型のモンテカルロ法／10.3 熱浴法のPythonコードとデータの準備／コラム：統計力学と場の量子論 第11章 Nature Physicsの論文を再現しよう 11.1 論文について／11.2 データの前処理／11.3 実験...',\n",
       " '機械学習の予備知識がない読者を、研究の最前線までしっかり連れて行く、ひとりでも学べる入門書！ 深層学習の理論を初めて学ぶ人はもちろん、今度こそ理解したい人のために。 【甘利俊一先生推薦】 「世の中に人工知能の解説書は多いが、基礎から始め、その仕組みを理論的に明快に説明したのは本書が初めてといってよい」...',\n",
       " '課題・疑問・質問・感想に明確に応える書...',\n",
       " '各種の最適化手法の原理や計算法をやさしく解説...',\n",
       " '最適化問題へのモデル化と、基本的なアルゴリズムを俯瞰し、最適化という考え方の基礎をしっかりと固める。具体例と演習問題も充実!...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 対話形式による解説で、数理モデルの基礎が身につく入門書。数理モデルとは、現実の世界で起こるさまざまな現象を数式で表したものです。数式にすることで、その現象の性質を理解したり、変化を予測したりできます。「どうやって価格を決めるの？」「売上を予測するには？」「広告で販売数を増やすには？」など、ビジネスパーソンにとって身近なテーマを題材に数理モデルを解説。数学記号の読み方や意味から丁寧に説明するので、不安な方もどうぞご安心を。とっつきやすいのに「数理モデルの考え方」がわかる一冊。...',\n",
       " 'データサイエンスの根幹をなす「数理モデル」がしっかり身につく!難しそうな問題も数理モデルで解決!...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 ビジネス現場ではデータ活用の重要性がますます高まっています。データに基づいた経営施策の実施とその効果検証のためには、一般的な統計指標（平均、標準偏差、相関）だけでなく「因果」にまで分析を広げる必要があります。 本書は因果分析の重要な2つの領域である「因果推論」および「因果探索」について、実際にプログラムを実装しながら学ぶ書籍です。因果推論や因果探索を学びたいビジネスパーソンや、初学者の方を対象としています。 ・因果推論とは「テレビCM放映で、商品購入量がどれくらい増えたのか？」「研修の実施で、社員スキルがどの程度向上したのか？」など、なんらかの施策を実施した際に、その施策の効果を推定する手法です。 ・因果探索とは「生活習慣と疾病の調査」「働き方改革に伴う社員調査」など、アンケート調査等で収集した各項目間の因果関係を明らかにする試みです。 本書は「因果推論、因果探索とはどのようなものか」「因果推論、因果探索を実施するには、具体的にどうしたら良いのか・分析プログラムをどう実装したら良いのか」「因果推論、因果探索が、どのように機械学習やディープラーニングと結びついているのか」が理解・習得できる内容となっています。 プログラミング言語Python、実行環境Google Colaboratory、機械学習ライブラリscikit-learn、PyTorchで実際に手を動かしながら実装し、習得していきます。 データに基づいた経営・ビジネスを実践するうえでスタンダードな手法となる因果分析をマスターしよう。 Part 1：因果推論 第1章 相関と因果の違いを理解しよう 第2章 因果効...',\n",
       " 'これ一冊あればGitはもうこわくない！ ※この電子書籍は固定レイアウト型で配信されております。固定レイアウト型は文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 Git入門の決定版！ バージョン管理システムであるGitとそれを最大限に活用するためのプラットフォームであるGithubの使い方を、ハンズオンで丁寧に解説。 SourceTreeを使った視覚的な操作から、コマンドラインを使ったスムーズな利用まですべてを網羅。 バージョン管理はもうこわくない！...',\n",
       " 'パターン認識を学ぶ入門書に最適。Rによる実行例も収録。...',\n",
       " 'はじめに,数学を丁寧に復習し,最適化直感的に理解できるよう,図形的説明を多用しながら,その全貌を分かりやすく詳説する....',\n",
       " '本書を読めば確率論の基本が理解できるように,証明などを丁寧に述べた初学者向け入門テキスト。...',\n",
       " '本書は、有意性検定やp値によらない統計学の教科書です。初めて統計学を学ぶ学生のための最初歩の入門書であり、独習書です。統計データ分析に関する予備知識はいっさい仮定せず、数学的説明には微分・積分・シグマ記号・行列・ベクトル演算を使わずに、統計的推測の世界にご招待いたします。...',\n",
       " '日本人が陥りがちな、躍動感や変化に乏しい表現、いわゆる日本語直訳的＝和製英文的な表現を修正し、どこに出しても恥ずかしくないプロフェッショナルな英語論文に仕立て上げるヒント満載。論文必須のパターン40表現と関連ボキャブラリー1000語句を収録しています。 英語論文にふさわしい明瞭簡潔な構文選択のコツに加え、スタイリッシュな見た目や必要不可欠な論文構成にも言及した、文系理系問わず、すべてのアカデミック・ライター必携の書。 【株式会社すばる舎】...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " 'なぜ、あなたのアイデアは組織の壁を突破できないのか?地方都市にありながらも全国から異才が集結する学校IAMAS(イアマス)。そこで培われた視覚的ブレインストーミング手法「アイデアスケッチ」のノウハウを、誰もが実践できるようわかりやすく解説。プロセスからデザインすることで、アイデアとチームを同時に醸成できる。...',\n",
       " 'オフラインがなくなる世界を「アフターデジタル」と呼んでいます。その世界を理解しその世界で生き残る術を解説します。...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 ホイールダック２号の冒険物語を通して、人工知能全般が学べる異色の教科書！位置推定、学習と認識、自然言語処理を中心に解説。ストーリー仕立てだから簡単に理解できる。まずは、この1冊から始めよう！...',\n",
       " '2進数から誤り訂正符号までを明快に説く、初学者にとって最良の教科書。...',\n",
       " '記述なし',\n",
       " 'ノーベル賞学者と第一人者による基本文献.主要概念の定義と分析の論理を詳述.待望の全訳....',\n",
       " '評判分類、単語の意味表現、検索結果の順序学習を重点的に解説した。話題を瞬時に発見するバースト検出やウェブのリンク解析も紹介。...',\n",
       " 'ウェブサイトのUX改善を題材に、メタヒューリスティクスなど機械学習のアプローチでパラメーターの抽出やモデルの選択などを学ぶ。...',\n",
       " '空間データの新たな解析法「エシェロン解析」について、基礎となる考え方やアルゴリズム、応用例やソフトウェアなどを紹介する。...',\n",
       " '絶えず流れる情報を、いかに捉え、いかに学習するか? 多彩なアルゴリズムを簡潔・丁寧に解説。基礎が理解でき、応用手法も身につく...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 誰でもすぐにオンライン機械学習を実践できる即戦力の入門書！オンライン機械学習の基礎から理論、実装、応用、最新手法までをすべて網羅し、明快に解説した。この１冊で、面白いほどよくわかる！...',\n",
       " '記述なし',\n",
       " '主にカルマンフィルタを用いた時系列解析の方法論と、データ解析の実践を解説。Rを用い、多種多様な時系列への対応を念頭に詳述。...',\n",
       " '基本的な考え方と手法の設計法を明快に説明...',\n",
       " 'カーネル法によるパターン解析を詳細に解説...',\n",
       " '原理、代表的手法、最近の発展を詳述する...',\n",
       " '圧倒的に柔軟なベイズ的回帰モデルであるガウス過程の日本初の入門書。基礎の線形回帰から始め、ガウス過程の原理をゼロからていねいに解説。教師なし学習、実応用など最近の話題まで紹介した。さあ、はじめよう！...',\n",
       " '料理を支える自然言語処理と画像処理を学ぼう！ クックパッドや楽天レシピなどのレシピサービスは、多くの方にとってなじみ深い、日常的に使用するものです。ほかにも、写真を撮るだけで食事が記録できるアプリや、トレーに載せた食品をスキャンすると精算ができる画像認識型のレジなど、身の回りには食に関係する情報技術が多数存在します。 本書は、そういったレシピや料理画像を題材として、言葉や画像を扱う技術について解説します。 たとえばクックパッドには、投稿されたレシピの文章を解析して、自動的にカテゴリ分けする機能があります。これには、自然言語処理という言葉を扱う技術が活用されています。 また、上で触れた食事が記録できるアプリなどには、投稿された料理写真を解析して、自動的に料理を認識する機能があります。これには、画像処理という画像を扱う技術が活用されています。 こういった自然言語処理や画像処理の技術を概説したのち、研究や開発に使用できるデータセットや、実際のサービスにおける活用事例を紹介します。さらに、自然言語処理と画像処理を複合的に用いる、クロスモーダルな処理についても紹介します。 また、最後には、自然言語処理や画像処理をより深く学びたい方に向けて、推薦図書の案内も掲載しています。 「まさに料理に関する情報サービスの開発に携わっている！」という方にはもちろんですが、これから自然言語処理や画像処理を学びたい方、言語と画像のクロスモーダルな処理について学びたい方、新しい研究テーマやサービス開発のアイデアを見つけたい方、さらには単純に料理とAIという組み合わせに興味のある方まで、技術に興味のある方には幅広く楽しんでいただける内容です。 このような方におすすめ ◎ 食に関係するデータ処理に興味をもっている方 ◎ 言語や画像の処理を行うエンジニア、リサーチャー ○ 情報系の学部、学科に所属する大学生 主要目次 第1章 はじめに――なぜ料理と情報処理なのか？ 第2章 料理と自然言語処理 第3章 料理と画像処理 第4章 料理とクロスモーダル処理――複合的なアプローチ 第5章 おわりに――料理と情報処理のこれから...',\n",
       " '(初版1999年10月刊行)統計解析およびデータ解析の一部門である,クラスタリング(クラスター分析)の代表的な手法を詳述した本です. 【目次】 第1章はじめに 第2章 c-平均法 第3章ファジィc-平均法 第4章混合密度分布モデルとEMアルゴリズム 第5章最適クラスタリングの諸技法 第6章クラスタリングのための類似度と非類似度 第7章階層的クラスタリング 第8章樹形図の出力 第9章最短距離法とファジィグラフ 第10章階層的クラスタリングの諸問題...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 各種グラフィカルモデルの紹介から、機械学習における使い方まで丁寧に解説する。この手法が有効な問題の見分け方、グラフの扱い、推論・学習に活かす方法など、必要なことをコンパクトにまとめた。...',\n",
       " '世界は「グラフ」でできている。ソーシャルネットワーク、交通ネットワーク、タンパク質の相互作用など、身の回りの様々な現象は、ノード(頂点)とエッジ(辺)から構成されるグラフによって記述することができる。本書はこのグラフを深層学習(ディープラーニング)に適用した「グラフ深層学習」を、初学者にも分かりやすく解説した入門書である。グラフ理論や深層学習の基礎からはじめ、グラフニューラルネットワーク(GNN)の理論的な側面やその実践的な応用例を幅広く取り上げている。自然言語処理、画像処理、データマイニング、生化学・ヘルスケアなど、様々な分野でのGNNの活用が理解できるようになってる。GNNに興味を持つ学生や研究者、さらには実際の業界でGNNを応用したいと考えている専門家にとって、理解の手引きとなる一冊である。...',\n",
       " '本書は、先端的なグラフ理論の全体像を把握するために書かれた教科書である。どの章も、その分野で何が問題になっているのかがわかる導入になっており、その精神が丁寧に書かれている。また、形式的な証明を与える前に、その直観的なアイディアが示されており、理解を助けてくれる。特に、最終章には、近年のグラフ理論の1つの指導原理となっているRobertsonとSeymourによるグラフ・マイナーの理論がまとめられている。...',\n",
       " 'あのOne Pointシリーズが統計学にも登場!第一弾はゲノムワイド解析(GWAS)からレアバリアント解析までポイントを絞って解説。...',\n",
       " '統計学習理論に基づく新世代学習システムを詳説...',\n",
       " 'わかりやすい、実にわかりやすい。解析ツールとして利用したい人が知っておくべきことを整理。多くの学習アルゴリズムを紹介しているので、実践的!構造化サポートベクトルマシン、弱ラベル学習など新しいアプローチも解説。...',\n",
       " 'Rを用いて統計学の基礎手法をシミュレーション...',\n",
       " '記述なし',\n",
       " 'スパース回帰分析、判別分析、深層学習、SVMなどの基本から、選ばれたモデルへの理解などの発展的な内容までを解説!...',\n",
       " 'スパースは絶対読まなきゃ!L1ノルム正則化の理論・モデリング・最適化法を丁寧に解説。「トレースノルム正則化」「アトミックノルム」などの発展的な内容も詳しい。...',\n",
       " '阪大教授Joe Suzukiが講義の演習問題を書籍化。Prof.Joeの100問でスパースの本質をつかむ!...',\n",
       " '統計学の基本ツールになりつつあるスパース推定について、統計モデリングを中心に入門的内容から発展的内容までを解説。...',\n",
       " '★★理論と実装のバランスがよい、「機械学習 with Python」の決定版★★ ■機械学習モジュールが普及することにより、かえって学びづらくなった機械学習アルゴリズムの基本を徹底マスター！ ■scikit-learnを使わない、numpyとpandasのみのコーディングで、実装力がスキルアップ！ ■ブラックボックスの中身を理解し、一生モノの知識を身につけよう！ 【本書のサポートページ】すぐに実践できるコードがWeb公開！ https://github.com/hhachiya/MLBook 【機械学習スタートアップシリーズ】 https://www.kspub.co.jp/book/series/S042.html 【主な内容】 第1章 機械学習とは何か 第2章 Python入門 第3章 数学のおさらい（線形代数、最適化、確率、統計） 第4章 回帰分析（線形回帰分析、ロジスティック回帰分析） 第5章 分類（線形判別分析、サポートベクトルマシン、ナイーブベイズ法、決定木） 第6章 カーネルモデル 第7章 ニューラルネットワーク 第8章 強化学習 第9章 教師なし学習（主成分分析、因子分析、クラスター分析）...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '日本語環境で実践している先駆者たちによる初の体系的解説書。...',\n",
       " '「テキスト(文字列)」「画像」「音声」を、いかにして解析するか? 3分野それぞれの専門家の筆を得て、系統的に解説する教科書。...',\n",
       " '記述なし',\n",
       " 'データ分析のための前処理の基礎とビジネス応用の実例を学ぶ。Pythonの基礎も付録に収録。...',\n",
       " 'ツールとして不可欠な技術をコンパクトに！ ・データベースの活用を目的とし、SQLの操作は「問い合わせ」を中心に、MySQLに準拠して解説！ ・関係データベースの基本とその使い方、データの可視化、NoSQLまで網羅！ ・実践的なデータ分析事例として、Wikipediaダンプデータの分析を紹介！ 【サポートページ】 https://sites.google.com/view/dbfordatascience 【主な内容】 1章 はじめに 2章 関係データベースの基本 3章 SQLと正規化 4章 データの可視化と分析 5章 NoSQL 6章 実践的データ分析事例 【「巻頭言」より抜粋】 文部科学省は「数理及びデータサイエンスに係る教育強化拠点」6 大学(北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学)を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。 本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。 データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 ――編集委員長 竹村彰通(滋賀大学データサイエンス学部学部長、教授) 【推薦の言葉】 データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。 ――北川源四郎(東京大学特任教授、元統計数理研究所所長) 国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。 ――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授)...',\n",
       " 'データサイエンスの門をたたく前に必要となる数学を、一冊にまとめたテキスト。微分積分・線形代数・確率論の中から、入門者が学んでおきたい基礎を厳選、平明簡潔に整理した。まずはこの本で、しっかり基礎固め！【データサイエンス入門シリーズ】第1期として、以下の3点を刊行!・『データサイエンスのための数学』椎名 洋・姫野哲人・保科架風（著）清水昌平（編）・『データサイエンスの基礎』浜田悦生（著）狩野 裕（編）・『最適化手法入門』寒野善博（著）駒木文保（編）【「巻頭言」より抜粋】データサイエンス分野の遅れを取り戻すべく、日本でも文系・理系を問わず多くの学生がデータサイエンスを学ぶことが望まれます。文部科学省も「数理及びデータサイエンスに係る教育強化拠点」6 大学（北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学）を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。――編集委員長 竹村彰通（滋賀大学データサイエンス学部学部長、教授） 【推薦の言葉】データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。――北川源四郎(東京大学特任教授、元統計数理研究所所長)国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授)...',\n",
       " '記述なし',\n",
       " '現実社会のデータを多く扱いながら、データサイエンスの概念と確率の基礎をしっかりていねいに解説。データリテラシーを涵養するためのまたとない入門書！ データサイエンスを知るならまずこの本！ 【データサイエンス入門シリーズ】第1期として、以下の3点を刊行! ・データサイエンスのための数学：椎名 洋・姫野哲人・保科架風（著）清水昌平（編）・データサイエンスの基礎：浜田悦生（著）狩野 裕（編）・最適化手法入門：寒野善博（著）駒木文保（編）／【「巻頭言」より抜粋】データサイエンス分野の遅れを取り戻すべく、日本でも文系・理系を問わず多くの学生がデータサイエンスを学ぶことが望まれます。文部科学省も「数理及びデータサイエンスに係る教育強化拠点」6 大学（北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学）を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 編集委員長 竹村彰通（滋賀大学データサイエンス学部学部長、教授） 【推薦の言葉】データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。――北川源四郎(東京大学特任教授、元統計数理研究所所長) 国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授)...',\n",
       " 'ビッグデータの時代だ。さまざまな分野の研究がデータ駆動型に変わってきている。ビジネスでのビッグデータ利用も人工知能の開発とあいまって盛んだ。データ処理、データ分析に必要な情報学(コンピュータ科学)、統計学の基本知識をおさえ、新たな価値創造のスキルの学び方を紹介する。待望の入門書。...',\n",
       " 'データ収集と分析に必要な知識とスキルについて、確率・統計の基礎から線形代数、統計分析など、広範囲にわたってカバーした一冊。...',\n",
       " 'Pythonによる機械学習モデル構築のための特徴量抽出・作成実践レシピ...',\n",
       " '基本事項から適用事例を平易に纏めた教科書...',\n",
       " '基礎からWeb、ソーシャルメディアまで...',\n",
       " '記述なし',\n",
       " '実務と手法をつないだベストセラー、待望の3訂版。ビッグデータへすぐに応用できるようケーススタディで解説。...',\n",
       " '統計学の本質を知らずに分析してませんか?統計モデルから機械学習モデル、数理モデルまで。データ分析に取り組む前に学ぶべき統計学を1冊に凝縮!基礎から発展的手法まで全く新しい教科書!...',\n",
       " 'そもそも、データ分析で何ができるのか。データ分析とは機械学習だけなのか。様々な分析手法の全体像と関係性は?データの背後に隠れた構造を知りたい。研究で使う解析手法について悩んでいる。データを分析する全ての人に贈る一冊です。...',\n",
       " '【データサイエンティストたちの悪夢】 ・上司が「AI使ってます」と言いたいだけのプロジェクト ・自分が期待した結果しか認めないクライアント ・プロジェクト終盤でもまだ手に入らないデータ ・分析手法にしか興味がない分析者 ・最終報告後にやっと決まる仕様 【その分析、もう失敗しているかも...... 失敗を回避し、成功に近づくためのガイド】 本書は、第一線で活躍するデータサイエンティストたちが経験した、データ分析プロジェクトの「失敗」をもとに再構成された25の事例が収録されている。これらの臨場感あふれる事例から、データの活用に関わる人たちが、失敗を避けるために何をしてはならないのか、について学びとることができる。プロジェクトの失敗の予兆となる致命的な要因を察知し、失敗に至る「毒薬」を飲まないように注意するための知見が本書には随所に含まれている。 データの活用に関わる分析者、そして、分析を依頼する立場となる経営者や企画部、マーケティング部に所属する方々に送る、失敗から学び、成功への道筋を描くための必読書――失敗は成功の母である!...',\n",
       " 'データ解析とシミュレーションを繋ぐ数理...',\n",
       " '記述なし',\n",
       " 'データ科学の基礎的な理論と手法を体系的に学ぶことで,基本となる思考プロセスを身につけられるよう構成されたわかりやすいテキスト....',\n",
       " '「仮名化/匿名化」「差分プライバシー」「秘密計算」を、統計学・データ工学・暗号理論の観点から丁寧に解説。データ解析実務者も必読。...',\n",
       " '現象を数理モデルで表現・説明するのに慣れていない人のために、章ごとに異なる例題を解決していく過程を通して、統計モデルの基本となる考えかたを紹介する。前半では、応用範囲のひろい統計モデルのひとつである一般化線形モデルの基礎を、後半では、実際のデータ解析に使えるように、階層ベイズモデル化する方法を、RとWinBUGSの具体例を用いて説明する。...',\n",
       " 'おそろしく親切、すさまじく丁寧。文書データにとどまらない活用の可能性が実感できる。統計の基礎から最新応用事例までがまとまった、待望の1冊。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '世界中で使われているノンネイティブのバイブル。これほど網羅的で深い示唆を与えてくれる指南書はほかにない。ワンランク上の論文に...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 さぁ、無限次元の扉を開こう！確率分布の基礎から時系列データやスパースモデリングへの応用までを明快に説く。理論的な背景である測度論も基礎から丁寧に解説する親切設計。新進気鋭のエース研究者が、満を持して執筆した。全ベイジアン必携！...',\n",
       " 'さまざまな方策が、定量的かつ直感的に理解できる。モンテカルロ木探索やインターネット広告などのより具体的な状況への対応も紹介。...',\n",
       " 'Rを利用してパターン認識の様々な方法を解説...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " 'ベイズ理論に基づく理論や手法を解説...',\n",
       " 'いま注目の手法、その基礎から構築まで。多クラス問題への拡張やモデルの評価など、SVM開発の指針となる解説が充実。...',\n",
       " '記述なし',\n",
       " '“人間と機械”を超えた、人工知能の新世界!基本概念から技術的課題とその解決方法までをわかりやすく解説。将来展望や研究動向も把握できる。...',\n",
       " '■マット・タディはビッグデータ活用の基礎を成す統計学について完璧かつ配慮の行き届いた本を書き上げた。この素晴らしい教材には実例、技術、洞察がぎっしりと詰まっている。多くの機械学習の教材とは異なり、本書は相関関係が因果関係ではないという問題に取り組み、データから信頼に足る解釈を得るための手法を提供している。 ———プレストン・マカフィー［元マイクロソフト チーフエコノミスト兼バイスプレジデント ヤフー バイスプレジデント・チーフエコノミスト グーグル研究責任者 カリフォルニア工科大学教授兼役員］ ■シカゴ大学ブース・スクール・オブ・ビジネスの人気教授を務め、マイクロソフトとアマゾンでデータサイエンスチームを率いた経験から、マット・タディは最先端の企業でデータに基づいた意思決定を行なうことを志すMBAや技術者に向けた見事な本を書き上げた。最新の統計学、機械学習アルゴリズム、社会科学の因果モデルから得られる重要な概念を巧みに織り上げ、精彩を放つタペストリーに仕上げている。本書を読めば流行りの専門語の意味が誰にでもわかるようになっている。この分野の標準的な教材となるだろう。 ———グイド・インベンス［スタンフォード大学経営大学院教授（経済学） 『Causal Inference for Statistics, Social, and Biomedical Sciences』共著者］ ビッグデータを構造的に理解、近未来の手がかり、ビジネスチャンスを洗い出し、次の一手につなげる 巨大IT企業アマゾン・ドット・コムのバイスプレジデントが教える、ビジネスにおける意思決定の最適化・自動化・加速化 【株式会社すばる舎】...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 ベイズ統計に基づくモデリングだからこそ、見えてくるものがある。いかにデータを集めるか？だった時代から、勝手に集まるデータをいかすには？に課題が変化しつつある今、時代に応じたマーケティングのための基本を紹介。...',\n",
       " '記述なし',\n",
       " 'フリーソフトで実データの解析を実践。強化学習、深層学習、etc...応用的な手法も網羅。体感しながら理解するビッグデータの解析に役立つ入門書。...',\n",
       " 'ブースティング技法の理論的研究を纏めた...',\n",
       " 'ブートストラップ法に関する本邦初の入門書...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '入門から分析事例までを紹介...',\n",
       " '統計学の応用範囲を大きく広げ、新しい地平を開いたベイズ法。歴史的なエピソードや、関連する理論と話題を詳しく解説する。...',\n",
       " '「読んでいて本当に心地がいい」と大好評の前著『ベイズ推論による機械学習入門』からの第２弾！ ｢深層学習とベイズ統計の融合｣がすべて詰まった ｢欲張り｣本！ 基礎からはじめ、深層生成モデルやガウス過程とのつながりまでをていねいに解説した。本邦初の成書！本書のサポートページ：https://github.com/sammy-suyama/BayesianDeepLearningBook 【主な内容】第1章 はじめに 1.1 ベイズ統計とニューラルネットワークの変遷 1.2 ベイズ深層学習／第2章 ニューラルネットワークの基礎 2.1 線形回帰モデル 2.2 ニューラルネットワーク 2.3 効率的な学習法 2.4 ニューラルネットワークの拡張モデル／第3章 ベイズ推論の基礎 3.1 確率推論 3.2 指数型分布族 3.3 ベイズ線形回帰 3.4 最尤推定，MAP推定との関係／第4章 近似ベイズ推論 4.1 サンプリングに基づく推論手法 4.2 最適化に基づく推論手法／第5章 ニューラルネットワークのベイズ推論 5.1 ベイズニューラルネットワークモデルの近似推論法 5.2 近似ベイズ推論の効率化 5.3 ベイズ推論と確率的正則化 5.4 不確実性の推定を使った応用／第6章 深層生成モデル 6.1 変分自己符号化器 6.2 変分モデル 6.3 生成ネットワークの構造学習 6.4 その他の深層生成モデル／第7章 深層学習とガウス過程 7.1 ガウス過程の基礎 7.2 ガウス過程による分類 7.3 ガウス過程のスパース近似 7.4 深層学習のガウス過程解釈 7.5 ガウス過程による生成モデル...',\n",
       " '記述なし',\n",
       " '「統計モデリングの世界」へのファーストブック。基礎から学べる超入門。チュートリアル形式だから、すぐに実践できる!統計、確率、ベイズ推論、MCMCの基本事項から、やさしくサポート!brmsやbayesplotなどのパッケージの使い方も、しっかり身につく!...',\n",
       " 'ベイズ統計学の基礎知識が深まるよう配慮...',\n",
       " 'ベイズ的統計モデリングとモデル選択基準...',\n",
       " '記述なし',\n",
       " 'ベイズ統計の基礎から応用までを集大成...',\n",
       " '母集団の特徴や、集団間の関係を効率的に推測することに都合のよいベイズ統計学を初歩から解説した入門書。いま手元にある事前情報を使いながら、ベイズの定理にもとづいて、確率的に推測を行うベイズ統計学の考え方を、できるだけわかりやすく述べる。...',\n",
       " 'ベイズ統計学の入門的解説書。従来の統計学である「フィッシャー‐ネイマン‐ピアソン理論」にも配慮しつつ、ベイズ統計学の見方・考え方を、さまざまな具体例を取り上げながら、数理的側面からやさしく丁寧に解説。適宜設けられた囲み記事に、関連トピック、およびさらなる発展的話題が取り上げられ、参考文献も充実している。...',\n",
       " '重要ポイントを例題を交えて簡明に解説...',\n",
       " '記述なし',\n",
       " '多数の応用例でMCMC法を徹底的に解説...',\n",
       " '購買履歴の評価からマーケティングミックスの最適化、ソーシャルネットワークのデータ分析まで 本書は、マーケティング分析を行う際の諸相それぞれに関するデータ分析手法について論じます。伝統的な統計手法から、現在注目されている最新の手法までを網羅しながら、入手できるデータをどのように分析し、料理するかのレシピとして活用されることを期待します。 本書の大きな特徴として、分析の方向性を定番的な手法で示した後、マーケティング視点での分析について紹介し、マーケティング分析において、各分析手法をどのように役立てるのかについて示します。 はじめに 第1章 マーケティングにおけるデータ分析 1.1 マーケティングとマーケティング・リサーチ 1.2 POS システムとID 付きPOS データの登場と活用 1.3 インターネットとマーケティング 1.4 ビッグデータ時代のマーケティング分析技術 第2章 マーケティング分析のためのデータ 2.1 マーケティング活動と消費者行動 2.2 消費者の購買プロセスの捉え方の変化 2.3 尺度について 2.4 インタビュー調査，アンケート調査データ 2.5 購買データ：POS データ，ID 付きPOS データ 2.6 スキャン・パネル・データ 2.7 購買行動に関連するデータ 2.8 顧客の行動・発信データ 第3章 記述統計：データの集計と可視化 3.1 データのクリーニングと加工 3.2 表によるデータの集計 3.3 グラフによるデータの可視化 3.4 一変量のデータの代表的な値を表す統計値 3.5 一変量のデータのばらつきを表す統計値 3.6 二変量間の統計値 第4章 推測統計：確率分布と統計的検定 4.1 確率変数と確率分布 4.2 離散確率分布 4.3 連続確率分布 4.4 中心極限定理と大数の法則 4.5 区間推定 4.6 統計的検定 4.7 過誤と検出力 第5章 売り場の評価 5.1 集計による売上の評価 5.2 売り場の計数管理 5.3 ABC 分析による重要カテゴリの評価 5.4 吸引力モデルによる商圏分析 5.5 回帰分析による売上予測 第6章 商品の評価 6.1 経営的視点からの商品の管理 6.2 主成分分析による商品の評価 6.3 相関ルール分析 6.4 コンジョイント分析による新商品企画の最適化 第7章 顧客の評価 7.1 顧客のセグメンテーション 7.2 優良顧客の評価 7.3 因子分析・共分散構造分析による顧客の潜在的ニーズの構造分析 7.4 確率選択モデルによる購買行動モデル 第8章 顧客志向のアプローチ 8.1 ターゲティング戦略の策定 8.2 対応分析による売り場配分策定 8.3 顧客へのレコメンデーション 8.4 潜在クラス分析による顧客の多様性の評価 第9章 ウェブ・マーケティング，ソーシャル・マーケティング 9.1 ネットワーク分析による消費者間の関係分析 9.2 テキスト・マイニングによるクチコミの解析 9.3 アクセス・ログ・データをもとにした顧客のサイト内行動分析 付録A 統計分布表 A.1 標準正規分布表 A.2 t 分布表 A.3 \\x1f2 分布表 A.4 F 分布表 A.5 ウィルコクソンの符号順位和検定のための数表 A.6 ウィルコクソンの順位和検定のための数表 付録B 数理モデルの詳細 B.1 不偏分散の導出 B.2 最尤法 B.3 回帰分析の数理 B.4 多項ロジット・モデルの算出 B.5 主成分分析の数理 B.6 因子分析の数理 B.7 対応分析の数理 B.8 EM アルゴリズム B.9 吸収マルコフ連鎖モデルの数理 参考文献 索引...',\n",
       " 'マーケティングデータ分析の基礎を学ぶ。...',\n",
       " '記述なし',\n",
       " '真の値や情報源を推定するモデルの最適化...',\n",
       " 'ベイズ統計を支えるMCMCをやさしく丁寧に! マルコフ連鎖モンテカルロ法（MCMC）が驚くほど真面目によくわかる！ 理解を助けるためのR言語のコードや章末の練習問題が充実！ モンテカルロ法の感覚を養ってもらうために「乱数の生成」を第2章で解説した。また，入門向けを標榜しながらも，後半の第4章以降では，和書で情報を得ることが難しい「エルゴード性」について踏み込んだ。 【主な内容】 1章 序論 2章 乱数 3章 積分法 4章 マルコフ連鎖 5章 ギフスサンプリング 6章 メトロポリス・ヘイスティングス法 【「巻頭言」より抜粋】 文部科学省は「数理及びデータサイエンスに係る教育強化拠点」6 大学(北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学)を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。 本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。 データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 ――編集委員長 竹村彰通(滋賀大学データサイエンス学部学部長、教授) 【推薦の言葉】 データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。 ――北川源四郎(東京大学特任教授、元統計数理研究所所長) 国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。 ――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授)...',\n",
       " '立ち現れる普遍性。広がる応用。物理学、学習理論、情報学、...さまざまな分野で顔を出す「ランダム行列」。その数理を紐解き統計物理・確率論との関わりも論じる。ランダム行列に初めて出会う人から研究で使う人にまで、広く役立つ一冊。...',\n",
       " '読んでわかるコードの重要性と方法について解説...',\n",
       " 'Pythonの型を用いてメンテナンスに適したコードを記述する方法を解説。基本的から静的解析や高度なテスト技法をまでを扱う。...',\n",
       " '一般化線形モデルの理論をしっかり解説...',\n",
       " '記述なし',\n",
       " 'データの情報を集約した総合指標を得る方法...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 ◆◆ロングセラー、10年ぶりの改訂◆◆ ・全ページをフルカラー化したので、図表もさらにわかりやすく！ ・非定常時系列データ解析の基本を加筆（第8章を新設） データの見方や考え方から述べられた本当にほしかった入門書。 それぞれがもつ「予測したい」課題に自ら取り組むための基本を１冊にまとめた。 「モデリングが使えるということはわかった、これからは使いたい！」という人は必読。 統計のプロ中のプロが伝授する「匠の技」「匠の知恵」コラムも多数収録。 【推薦の言葉】 本書は予測のための統計的モデリングの方法を，基礎から具体的実践例に亘るまで明快に解説している特色ある著作である． 平易な記述でベイスの定理などの基礎から粒子フィルタやデータ同化などの先端的な内容までをカバーしている． 便利なブラックボックス型のAI予測では飽き足らず，自分が抱える具体的な課題に対して自らのアイデアを投入し，説明可能な予測をしてみようと思い立った人には必読の書である． ――北川 源四郎先生(東京大学特任教授、数理・データサイエンス教育強化拠点コンソーシアム 議長) 【まえがき（抜粋）】 統計学の強みは，生成モデルの構築に関する，さまざまな知見とノウハウの蓄積，またモデルに基づく意思決定の綿密な評価にある．ある種，モデリングに関する匠の技とも言える暗黙知に，統計学の存在感が増していくであろう．読者が本書を通じてこの暗黙知を習得されることを期待したい． 【目次】 〈基礎編〉 第1章 予測とは何かを考える 第2章 確率による記述：基礎体力をつける 第3章 統計モデル：予測機能を構造化する 第4章 計算アルゴリズム1：予測計算理論を学ぶ 〈展開編〉 第5章 計算アルゴリズム2：モデルを進化させる 第6章 粒子フィルタ：予測計算を実装する 第7章 乱数生成：不確実性をつくる 〈実践編〉 第8章 時系列解析の基本：傾向をつかむ 第9章 経験知の総結集：売上予測の精度を上げる 第10章 データ同化：シミュレーションの予測性能を向上させる 第11章 確率ロボティクス：お掃除ロボをつくる ※この商品は紙の書籍のページを画像にした電子書籍です。文字だけを拡大することはできませんので、タブレットサイズの端末での閲読を推奨します。また、文字列のハイライトや検索、辞書の参照、引用などの機能も使用できません。...',\n",
       " '具体的な事例を通してテキストマイニングを解説...',\n",
       " '記述なし',\n",
       " '機械学習やデータ分析の道具をどのようにビジネスに生かしていけば良いのか、「仕事で使う」という観点から整理。...',\n",
       " 'イラストで、1歩目から少しずつ。これならDockerがわかる!...',\n",
       " '数学と学習理論の関係を明快に解説...',\n",
       " '記述なし',\n",
       " '大家Pearlによる入門書。統計的に原因を推定する考え方を,図と言葉で丁寧に解説。...',\n",
       " '記述なし',\n",
       " 'ベイズ統計についてわかりやすく解説した...',\n",
       " 'Pythonの数列と演算について丁寧に説明。NumPyを使いこなして科学計算や複雑な計算を楽に行う知識とスキルをマスターする。...',\n",
       " '記述なし',\n",
       " '自然言語処理の概念から実践までを詳説...',\n",
       " '「具体と抽象（の往復）」。その思考回路を持つと、あなたの知的能力は劇的に進化する！ 「具体⇔抽象」とは、抽象化と具体化という形で具体と抽象を行き来する思考法のこと。斬新な発想をできるようになるだけでなく、無用な軋轢やコミュニケーションギャップの解消にも役立ちます。そこで本書では、「抽象化と具体化の基本動作」から「仕事・日常生活における実践・応用の仕方」まで解説するとともに、トレーニング問題も多数用意しました。 ●問題：「目覚まし時計」「懐中電灯」「旅行代理店」「カメラ」「お金」の共通点は？ ●問題：「自動車の座席」と「年末に配られるカレンダー」の共通点は？ ●問題：「理系」と「文系」の違いは何でしょうか？ ●問題：「成功」の反意語は何でしょうか？ ●問題：「現象と理論」「一般論と例外」「チャーハンと中華料理」「物々交換と貨幣取引」……どちらが具体で、どちらが抽象でしょうか？ こうした問題を解くうちに「具体⇔抽象」の思考回路が身につき、「自分の頭で考える力」が飛躍的にアップする一冊！ 【PHP研究所】...',\n",
       " '記述なし',\n",
       " 'データの取得・分析・解釈・活用の各段階で知っておくべき技術を網羅的に解説!データ分析者必携の全く新しい教科書!...',\n",
       " '本書は、可能なかぎり少ない予備知識で、多変量解析の理解を解説しようと試みたものである。本書の特徴は、限られた条件のもとでのわかりやすさを重視したことである。著者が作成したきわめて人工的なデータは、単純で読者が容易に利用できるように工夫されている。読者は、もし、数式による解説が苦手ならば、各事実をデータ上で確かめてみることができる。...',\n",
       " '深淵な基礎理論が丁寧な展開ですっきりわかる。実用的なアルゴリズムを中心に紹介。構造正則化学習への道も具体的手順とともに解説。...',\n",
       " '「バイアス」を取り除くための技術。データによる裏付けがないことで、効果の質が問題になることは少ない。正しく比較ができていないため、因果関係を示すことができていないことの方が多い。...',\n",
       " '反実仮想(Counterfactual)─ 起こり得たけれども実際には起こらなかった状況 ─ に関する正確な情報を得ることは、機械学習や意思決定最適化の応用において必要不可欠です。例えば、「現在運用している推薦アルゴリズムを仮に別のアルゴリズムに変えたとしたら、ユーザの行動はどのように変化するだろうか?」や「仮にある特定のユーザ群に新たなクーポンを与えたら、収益はどれほど増加するだろうか?」「仮に個々の生徒ごとに個別化されたカリキュラムを採用したら、1年後の平均成績はどれほど改善するだろうか」などの実務・社会でよくある問いに答えるためには、反実仮想に関する正確な情報を得る必要があります。こうした反実仮想の推定や比較に基づく意思決定の最適化を可能にするのが、反実仮想機械学習(CounterFactual Machine Learning; CFML)と総称される機械学習と因果推論の融合技術です。 反実仮想機械学習は、何らかの意思決定の最適化やその性能評価を行うすべての機械学習エンジニア・データサイエンティストに必要不可欠な考え方と基盤技術を提供します。しかし、予測や最適化、典型的な因果推論などすでに多く語り尽くされた話題に関する文献は増え続ける一方で、急速な発展を見せる反実仮想機械学習に関する体系的な記述や要約は、未だこの世に存在しないのが現状です。本書では、反実仮想機械学習の基礎的な考え方と最新技術を世界に先駆けて体系化することで、この看過できない現状を打破することを目指します。特に本書では、反実仮想機械学習の重要な基礎であるオフ方策評価と呼ばれる統計的推定問題を重点的に扱い、反実仮想に関する情報を観測データに基づいて正確に推定するために必要な考え方と統計技術を着実に身につけます。その後、オフ方策評価の自然な拡張として、観測データに基づく意思決定の最適化問題を扱います。こうして、反実仮想推定を最重要の基礎に据える反実仮想機械学習の思想と理論、それらの汎用的な応用力を身につけることが、本書における最大の目標です。 なお本書では、反実仮想機械学習に関する理論やその実践、Pythonを用いた実装をバランスよく扱っています。例えば、関連の学術研究や論文執筆を行いたい方向けには、理論に関する理解を深めるのに役立つ章末問題を提供しています。また本書6章には、機械学習や因果推論の実践現場で働く方々向けに独自に作成したケース問題を用いた反実仮想機械学習の応用例を示しました。そのため本書は、当該分野に関連する学術研究を行いたい学生・研究者の方やその実応用を行いたい実務家の方など、幅広い層や用途に有効活用していただける内容に仕上がっています。...',\n",
       " '★この本を買わずして何を買う！！★ 競技プログラミング経験が豊富な著者が、「アルゴリズムを自分の道具としたい」という読者に向けて執筆。入門書を標榜しながら、AtCoderの例題、C++のコードが充実。入門書であり実践書でもある、生涯役立つテキストを目指した。 【推薦の言葉】 プログラムが「書ける」ことと、効率の良い結果を得ることには大分ギャップがある。本書は、どのようにすれば効率のよい結果が得られるか？ すなわちどのようなアルゴリズムを採用すればよいか？ という点に対して、幅広くかつ明快に解説している。 また本書は、アルゴリズム初心者に対して、アルゴリズムへの興味を惹かれるように記述されている。アルゴリズム上級者への初めの一歩には最適であろう。 ――河原林健一（国立情報学研究所副所長） 【全体を通して、アルゴリズムの設計技法を重視した構成】 まず、1、2章でアルゴリズムと計算量について概観します。そして、3～7章が、早くも本書のメインパートといえる部分であり、「アルゴリズムの設計技法」について詳しく解説します。これらの設計技法に関する話題は、多くの書籍では、最後の方で簡単に説明しています。しかし本書は、現実世界の問題を解決するための実践的なアルゴリズム設計技法の鍛錬を目指しています。そこで、アルゴリズム設計技法について前半で詳しく解説する構成としました。そして、これらの設計技法が後半の章でも随所に使われていくことを示していきます。 その後、8～11章では、設計したアルゴリズムを効果的に実現するうえで重要となるデータ構造を解説します。データ構造について学ぶことで、アルゴリズムの計算量を改善したり、また、C++やPythonなどで提供されている標準ライブラリの仕組みを理解して、それらを有効に活用したりすることができるようになります。 そしていったん、12章でソートアルゴリズムについての話題を挟んだ後に、13～16章でグラフアルゴリズムについて解説します。グラフは、非常に強力な数理科学的ツールです。多くの問題は、グラフに関する問題として定式化することで、見通しよく扱うことができるようになります。また、グラフアルゴリズムを設計するとき、3～7章で学ぶ設計技法や、8～11章で学ぶデータ構造が随所で活躍します。 最後に、17章で PとNPに関する話題を解説し、世の中には「効率的に解くアルゴリズムを設計することができそうにない難問」が多数あることを見ます。18章で、これらの難問に取り組むための方法論をまとめます。ここでも、動的計画法 (5章) や貪欲法 (7章) といった設計技法が活躍します。...',\n",
       " '記述なし',\n",
       " 'キーワードベースで基礎知識やコア技術をわかりやすく理解できる!就職・転職を目指す学生やエンジニアから関連部門の営業やビジネスマンまで、技術の必須知識をまるごと理解!!...',\n",
       " '記述なし',\n",
       " 'ランレングス符号化、ワイル符号化、LZ符号化など可逆圧縮の基礎から、ウェーブレット変換を用いた非可逆圧縮まで、豊富なプログラム例により徹底解説。...',\n",
       " '21世紀の現代社会において、データ分析の多くの実践的現場では、すでにベイズ統計学が主流になっています。迷惑メールフィルタや画像音声のノイズ除去など、ベイズ統計学のない日常はもはや私たちには考えられません。またこの流れは決して止まらないでしょう。しかし、現在、特に文科系の大学における統計学教育の中でベイズ統計学の学習は十分とは言えません。技術的困難さが解決されたいま、社会・人文・行動科学の学部教育のなかで、ベイズ統計学の教育を充実させることは社会的急務です。本書は、文科系・理科系を問わず、ベイズ統計分析に入門を希望している方を読者として歓迎します。...',\n",
       " '有効な近似手法なくして、実問題の解決なし。ベイズ学習の基礎からはじめる親切な構成。「共役性」と「制約の設計指針」に焦点を当てた。変分ベイズ学習アルゴリズムの導出を丁寧に解説。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '諸科学，産業界のあらゆる分野で，複雑な多次元データから情報やパターンを抽出する必要性は増すばかりである．本書では，回帰モデルやベイズ判別，主成分分析，サポートベクターマシーンによる判別法などさまざまな解析手法について，単変量から多変量，二群から多群，線形から非線形への展開を，実例とともに平易に解き明かす．※この電子書籍は「固定レイアウト型」で作成されており，タブレットなど大きなディスプレイを備えた端末で読むことに適しています．また，文字だけを拡大すること，文字列のハイライト，検索，辞書の参照，引用などの機能は使用できません．...',\n",
       " '多変量解析を簡単な例を用いて平易に解説...',\n",
       " '基礎理論とRを使ったデータ分析の方法を解説...',\n",
       " 'アナログからデジタルの大きな変遷について、その同時代を生きてきた著者がユニークに解説。物理学的な側面からも説明する。...',\n",
       " 'ChatGPTに代表される大規模言語モデルが自然言語処理の幅広いタスクで高い性能を獲得し、大きな話題となっています。大規模言語モデルは、大規模なテキストデータで訓練された大規模なパラメータで構成されるニューラルネットワークです。2020年以降、自然言語処理や機械学習の知見をもとに、パラメータ数とテキストデータの拡大により、性能が飛躍的に向上しました。 Hugging Face社の\"transformers\"というPythonライブラリを利用することで、プログラミングの経験があれば、モデルの操作やデータからの学習がかんたんにできます。モデルを訓練するための日本語もしくは日本語を含む多言語のデータセットも充実してきており、すぐに業務に使える実用的なモデルを作ることが可能な時代がやってきました。 本書は、大規模言語モデルの理論と実装の両方を解説した入門書です。大規模言語モデルの技術や自然言語処理の課題について理解し、実際の問題に対処できるようになることを目指しています。以下のような構成によって、理論とプログラミングの双方の側面から、大規模言語モデルに関する情報を提供します。 第1章はじめに 第2章 Transformer 第3章大規模言語モデルの基礎 第4章大規模言語モデルの進展 第5章大規模言語モデルのファインチューニング 第6章固有表現認識 第7章要約生成 第8章文埋め込み 第9章質問応答システム...',\n",
       " '統計学が過去六十年間にどのように進化してきたかを検証し、広範囲に俯瞰。発展に影響があったトピックスについて年代順に解説する。...',\n",
       " '未来への発展の基礎となる話題を紹介...',\n",
       " '記述なし',\n",
       " 'GAN:敵対的生成ネットワークの初歩から理解し実装できる!...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '工学系の学部生・大学院生やエンジニアを対象に、最適化手法や最適設計法をわかりやすく解説する。理論と実践を兼ね備えた教科書。...',\n",
       " '学ぶ側の視点から丁寧に分かりやすく解説...',\n",
       " '理論は裏切らない！ ・強化学習で必要になる数理を広くカバーした。・一貫したていねいな解説なので、じっくり読める。付録・参考文献も充実！・ベルマン方程式、TD学習、方策勾配、POMDP、深層強化学習をより深く！／【おもな内容】 第1章 準備 1.1 強化学習とは 1.2 マルコフ決定過程と逐次的意思決定問題 1.3 方策 1.4 逐次的意思決定問題の定式化 第2章 プランニング 2.1 準備 2.2 動的計画法 2.3 動的計画法による解法 2.4 線形計画法による解法 第3章 探索と活用のトレードオフ 3.1 概要 3.2 探索と活用のトレードオフ 3.3 方策モデル 第4章 モデルフリー型の強化学習 4.1 データにもとづく意思決定 4.2 価値関数の推定 4.3 方策と行動価値関数の学習 4.4 収束性 4.5 アクター・クリティック法 第5章 モデルベース型の強化学習 5.1 問題設定の整理 5.2 環境推定 5.3 ブラックボックス生成モデルに対するプランニング 5.4 オンラインのモデルベース型強化学習 第6章 関数近似を用いた強化学習 6.1 概要 6.2 価値関数の関数近似 6.3 方策の関数近似 第7章 部分観測マルコフ決定過程 7.1 部分観測マルコフ決定過程（POMDP）の基礎 7.2 POMDP のプランニング 7.3 POMDP の学習 第8章 最近の話題 8.1 分布強化学習 8.2 深層強化 学習付録A 補足A.1 証明 A.2 ノルム A.3 線形計画法 A.4 自然勾配法の補足...',\n",
       " '本書は、“情報理論の基礎から説き起こしながらも、それにとどまらず最先端の研究成果までを確実に身につけられる”ことを目的に書きおろしたもので、実際に使いこなせる情報理論の本格的教科書である。斯界を代表する情報理論の研究者2人の手による完成度の高い内容である。...',\n",
       " '基本技術から最先端のトピックまで体系的に解説...',\n",
       " '記述なし',\n",
       " '情報検索の基礎を扱った網羅的で最先端の入門書...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '「情報理論のバイブル的名著」の待望の翻訳版...',\n",
       " '情報理論の隣接テーマを含めやさしく解説...',\n",
       " '情報理論は、1948年にシャノンが“A mathematical theory of communication”として世に送り出してから半世紀以上が過ぎ、いまや情報科学・情報工学の基盤をなす揺るぎない理論体系にまで発展を遂げている。本書は、情報理論の初学者を対象とした正統的テキストで、情報を記録・保存するための情報源符号化理論と通信路を経て情報を伝達するための通信路符号化理論の二つの主題を詳細に平易に解説する。...',\n",
       " '具体例と応用問題を織りまぜて基礎から解説...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '機械学習アルゴリズムへの情報論的アプローチ...',\n",
       " 'I・II巻を通じ現代統計学の進展方向、統計情報処理システムの形成へ向けての課題と展望を提示。...',\n",
       " '最良情報データ抽出の数理的判断規準を示す...',\n",
       " '《予測を「作る」から「使う」へ》 ・具体的な数値例，Pythonプログラミングを通して，手を動かしながら学ぶ！ ・決定分析の基本と活用を中心に，効用理論，確率予測までを解説！ ・リスクや不確実性がある中での意思決定に興味がある人に最適！ 【サポートページ】 https://logics-of-blue.com/decision-analysis-and-forecast-book-support/ 【キーワード】 ▼決定分析の基本 決定問題・期待値・展開型分析・相互情報量・KL情報量・情報の価値 ▼決定分析の活用 予測の評価・コスト/ロスモデル・標準型分析・ベイズ決定・逐次決定 ▼効用理論入門 選好・効用関数表現・期待効用最大化の原理・vNMの定理・リスク態度 ▼確率予測とその活用 確率予測の基本・信頼度・ブライアスコア・ROC曲線・最適な決定方式 【目次】 第1部 序論 第1章 意思決定における予測の活用 第2章 決定分析の役割 第2部 決定分析の基本 第1章 決定分析の初歩 第2章 Pythonの導入 第3章 決定分析におけるPythonの利用 第4章 期待値に基づく意思決定 第5章 情報の量 第6章 情報の価値 第3部 決定分析の活用 第1章 予測の評価 第2章 コスト/ロスモデルと予測の価値 第3章 決定分析の事例 第4章 標準型分析 第5章 逐次決定問題における予測の活用 第4部 効用理論入門 第1章 選好と効用関数表現 第2章 期待効用理論 第5部 確率予測とその活用 第1章 確率予測の基礎 第2章 確率予測の活用...',\n",
       " '推薦システムを「実際のビジネスに活かす」ことを目的に、ビジネス的な仮説や問題設定の仕方、プロジェクトの進め方を解説。...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 ◆「数理・データサイエンス・AI（リテラシーレベル）モデルカリキュラム」に完全準拠した公式テキスト！！◆ 【安宅和人氏（慶應義塾大学教授・ヤフーCSO）推薦！！】 「どこからデータサイエンスを？」と悩む人は、まずこの一冊を手に取るべし。 ・大学生はもちろんビジネスパーソンも、いますぐ知っておくべき教養がここにある。 ・「数理・データサイエンス・AI（リテラシーレベル）モデルカリキュラム」のうち「導入」「基礎」「心得」に完全準拠。 ・文理を問わず、すべての大学生に、数理・データサイエンス・ＡＩを習得させることを目的として編纂された。 ・カラーで見やすく、練習問題も充実。 【主な内容】 第1章 ［導入］ 社会におけるデータ・AI利活用 1.1 社会で起きている変化 （樋口知之） 1.2 社会で活用されているデータ （樋口知之） 1.3 データ・AIの活用領域 （孝忠大輔） 1.4 データ・AI利活用のための技術 （内田誠一） 1.5 データ・AI利活用の現場 （丸山 宏） 1.6 データ・AI利活用の最新動向 （内田誠一） 第2章 ［基礎］ データリテラシー 2.1 データを読む （川崎能典） 2.2 データを説明する （椎名 洋） 2.3 データを扱う （川崎能典） 第3章 ［心得］ データ・AI利活用における留意事項 3.1 データ・AIを扱う上での留意事項 （中川裕志） 3.2 データを守る上での留意事項 （佐久間淳）...',\n",
       " '論文・レポートの執筆、教科書・プリントの作成など、数式や数学用語を用いた文章を書く機会は案外多い。しかし、数式の表す内容にあいまいさがないからといって、その文章自体がわかりやすいとは限らない。“読者のことを考える”という原則に立って書くなら、もっと明解でもっとよく伝わる文章になるかもしれない。『数学ガール』シリーズを執筆し、文章の読みやすさに定評のある著者が自らの経験で培ったノウハウを伝授。本書「基礎編」では文章の順序、数式・命題の書き方、わかりやすい例の作り方、目次・索引の作り方などについて、豊富な具体例をもとに解説する。...',\n",
       " '最適化問題の種類は多数あり、さらにその種類ごとにアルゴリズムが複数存在する。実務家が最適化を使いこなすために、最適化ソルバーの背景にある理論およびアルゴリズムについて知っておくべき必要最小限の内容を整理した。「つくる」より「使う」立場なら、これで知っておくべきことがわかる。...',\n",
       " '数理系の学生から各分野の研究者まで、統計学の現代的手法を基礎から本格的に学びたい人のための参考書。 ※この電子書籍は固定レイアウト型で配信されております。固定レイアウト型は文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 数理系の学生から各分野の研究者まで、統計学の現代的手法を基礎から本格的に学びたい人のための参考書（初版1990年）。2003年発行の改訂版では、確率数学・情報数学の基本的な概念を使って、統計学の数理を明解に論じ、統計解析の章を充実させた。 「第1章 確率変数と確率分布」では、大数の法則と中心極限定理、ポアソン過程とガウス過程に触れ、確率論や確率過程への一歩にもなるように心がけた。 「第2章 統計的推測」では、情報量と決定原理を取り上げ、統計的推測の数理を明確にした。 「第3章 統計解析」では、直線回帰の項を設け、また回帰分析を全面的に書き直し、尤度解析の節を充実することにより、統計モデルによるデータと母数との聞の情報のやりとりが実験できることを目標にした。...',\n",
       " '数理系の学生から各分野の研究者まで、統計学の現代的手法を基礎から本格的に学びたい人のための参考書。 ※この電子書籍は固定レイアウト型で配信されております。固定レイアウト型は文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 数理系の学生から各分野の研究者まで、統計学の現代的手法を基礎から本格的に学びたい人のための参考書（初版1990年）。2003年発行の改訂版では、確率数学・情報数学の基本的な概念を使って、統計学の数理を明解に論じ、統計解析の章を充実させた。 「第1章 確率変数と確率分布」では、大数の法則と中心極限定理、ポアソン過程とガウス過程に触れ、確率論や確率過程への一歩にもなるように心がけた。 「第2章 統計的推測」では、情報量と決定原理を取り上げ、統計的推測の数理を明確にした。 「第3章 統計解析」では、直線回帰の項を設け、また回帰分析を全面的に書き直し、尤度解析の節を充実することにより、統計モデルによるデータと母数との聞の情報のやりとりが実験できることを目標にした。...',\n",
       " '記述なし',\n",
       " '基礎から最新手法まで幅広い領域を詳細解説...',\n",
       " '記述なし',\n",
       " '「バイアス」に惑わされない臨機応変な機械学習の応用技術。これまで素通りされてきた「予測の前段階」に焦点を当て、データ分析者としての新たな腕の見せ所を浮かび上がらせる。...',\n",
       " '記述なし',\n",
       " '本書はVC++ 2010を、入門者用に、総合的に体系的に解説したものです。VC++ 2010の機能を整理し、入門者にとって必要な項目を、環境操作から、プログラミングまで、順序正しく、漏れることなく取り上げ、具体的に、実用的に説明します。また本書を読み進めるためには、C++言語そのものの知識も必要です。そこで本書は、Visual C++ユーザーのために必要なC++言語の知識についてもコンパクトに説明しています。...',\n",
       " '時系列データはどのように分析されるべきか。分析の“フレームワーク”を基礎から丁寧に解説。...',\n",
       " 'これまでに時系列解析を理解しようとして挫折してきた読者も、基礎から本質まで理解できる、時系列解析待望の書。...',\n",
       " '記述なし',\n",
       " '現代統計学のツールとして使われている最小二乗法・交互最小二乗法の原理を理解し、理論から応用までポイントを絞って解説。...',\n",
       " '記述なし',\n",
       " '最適化理論の基礎からアルゴリズムにいたる全貌...',\n",
       " '「最適化」を使うことを目指して、さまざまな最適化モデルを解説した。理論は必要最低限にとどめ、具体的な例とＰｙｔｈｏｎコードを多く掲載している。東京大学のＵＴｏｋｙｏＯＣＷの講義映像「数理手法３」とも連携！ 【データサイエンス入門シリーズ】 第1期として、以下の3点を同時刊行! ・データサイエンスのための数学：椎名 洋・姫野哲人・保科架風（著）清水昌平（編） ・データサイエンスの基礎：浜田悦生（著）狩野 裕（編） ・最適化手法入門：寒野善博（著）駒木文保（編） 第2期の刊行は2019年11月の予定(^o^)/ 【「巻頭言」より抜粋】 データサイエンス分野の遅れを取り戻すべく、日本でも文系・理系を問わず多くの学生がデータサイエンスを学ぶことが望まれます。 文部科学省も「数理及びデータサイエンスに係る教育強化拠点」6 大学（北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学）を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。 本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。 データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 ――編集委員長 竹村彰通（滋賀大学データサイエンス学部学部長、教授） 【推薦の言葉】 データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。 ――北川源四郎(東京大学特任教授、元統計数理研究所所長) 国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。 ――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授)...',\n",
       " '最適化の基礎理論と解法を紹介する入門書...',\n",
       " '★まずは、この一冊から始めよう！★ 最適輸送は、ふたつの確率分布を比較するためのツールです。深層学習の勃興とGPU計算の普及により、機械学習分野でも最適輸送が広く用いられるようになりました。 本書では、線形代数・確率・最適化についての初歩的な知識を前提として、線形計画、エントロピー正則化、シンクホーンアルゴリズム、敵対的ネットワーク、スライス法などのさまざまな解法アプローチをていねいに解説します。 【主な内容】 第1章 確率分布を比較するツールとしての最適輸送 第2章 最適化問題としての定式化 第3章 エントロピー正則化とシンクホーンアルゴリズム 第4章 敵対的ネットワーク 第5章 スライス法 第6章 他のダイバージェンスとの比較 第7章 不均衡最適輸送 第8章 ワッサースタイン重心 第9章 グロモフ・ワッサースタイン距離 第10章 おわりに...',\n",
       " '記述なし',\n",
       " '東大 松尾研究室が提供するあの人気講座が待望の書籍化！ 本書は、2017年と2018年に東京大学で実施された「グローバル消費インテリジェンス寄付 講座」の学生向けオフライン講義と、社会人向けオンライン講座で使われた教材がベースになっています。 約400名ほどの受講枠（2年間）に、のべ1,800人以上の応募があった人気の講義です。この本のベースとなるコンテンツはJupyter Notebook形式で公開されていますが、この内容をさらに精査、ブラッシュアップし、読みやすく整えたものが本書になります。 ●本書の内容 本書には、データサイエンティストになるための基礎をつめこんでいます。データサイエンティストは、Pythonや確率・統計、機械学習など、幅広くさまざまな分野の知識を必要とします。 すべての分野を1冊で学ぶことは無理ですので、各分野で深入りはせず基礎的な事項を取り扱っています。データサイエンティストになるための地図と羅針盤のような位置づけとなることをイメージしています。 この本は主にPython 3を使って、基本的なプログラムの書き方、データの取得、読み込み、そのデータ操作からはじまり、さまざまなPythonのライブラリの使い方、確率統計の手法、機械学習（教師あり学習、教師なし学習とチューニング）の使い方についても学びます。取り扱っているデータは、マーケティングに関するデータやログデータ、金融時系列データなどさまざまで、モデリングの前にそれらを加工する手法も紹介しています。データサイエンティストになるには、どれも必要なスキルです。 本書には、さらに以下の3つの特徴があります。 ・実際のデータを使って手を動かしながら、データサイエンスのスキルを身に付けることができる ・データ分析の現場で使える実践的な内容（データ前処理など）が含まれている ・練習問題や総合問題演習など実際に頭を使って考える内容がたくさんある この本に書いてあることを実践し、読み終えた後には、実際の現場でデータ分析ができるようになるはずです。 ●この本の対象読者 この本は、プログラミングの経験があり、理系の大学1～2年生程度の教養課程の数学（線形代数、微分積分学、確率統計の基礎など）を終えている方を対象にしています。具体的には、勉強熱心な大学3～4年生の理系の学生さんや大学院生の方、また社会人になってデータサイエンスを学ぼうという意欲の高い方たちが対象です。データサイエンスの入門レベルから中級レベルの手前までを考えている人に最適で、本書のゴールもデータサイエンス入門レベルを卒業できることを想定しています。 ●著者による「はじめに」より編集・抜粋 世の中は多種多様でさまざまな問題があります。非効率的な仕事や処理、無駄があることもご承知の通りです。人工知能等が注目される一方で、いろいろな誤解や過剰な期待がされていることもあります。この本を手にとってくださっている方たちには、このような状況でも現実的になって、データサイエンスや人工知能等を使って何ができて何ができないのか、ぜひ見極めてください。 この読者の方たち、受講生の方たちの中から、このデータサイエンスの力を活かして、今の世の中の無駄や非効率を少しでもなくし、さらに新しい価値を創り出して、この世界を良くしていく人が増えていってくれたら、著者としては本望です。 ●本書で学べること ・Python/Numpy/Scipy/Pandas/Matplotlibの基礎 ・確率/統計/推定/回帰の基礎 ・Numpy/Scipyによる科学計算 ・Pandasを使ったデータ加工処理（欠損データ/異常値の取り扱い、時系列データの取り扱い） ・Matplotlibによるデータ可視化 ・機械学習（重回帰、ロジスティック回帰、決定木、k-NN、クラスタリング、主成分分析、マーケットバスケット分析、モデルチューニング）...',\n",
       " 'ベイズ統計の基礎と計算手法を効率的に習得できるテキスト。Rのサンプルコードも入手可能。...',\n",
       " '本書では、樹木構造接近法に関する著者らの総合報告に基づいて、個々の手法に関する具体的内容を取り扱う。樹木構造接近法およびアンサンブル学習法の理論的な背景、および周辺手法に関する話題も取り上げた。...',\n",
       " '記述なし',\n",
       " 'データ分析技術の中心には、分析アルゴリズムやモデリング手法があります。しかし実務の現場では、むしろ「前処理」の重要性に直面します。その方法は「分析目標」と「データ形式」によって異なり、そこからどのように特徴量を作り出すかで、機械学習の成否が左右されます。本書では「予測」を分析目標とし、構造化データ、画像データ、時系列データ、自然言語について、機械学習における前処理の手順を紹介。演習問題を経て、Pythonによる実装までを体験します。データ分析のフレームワークCRISP‐DMに沿って実装を進めるので、実務に近い形で前処理のテクニックが身に付きます。...',\n",
       " '機械学習の必須の技術であるカーネルを,その数学的基礎である関数解析から理解。Pythonコードを動かしながら身につける一冊。...',\n",
       " 'まずは、ここから。なんでも基礎が大切!機械学習の理解に必要なトピックを厳選した。機械学習を学びたい大学生・技術者向け。...',\n",
       " 'ベイズモデル、生成AIの数学的動作原理を学ぶ 本書は，機械学習の道具として使われている確率過程の書籍です．確率過程とは，誤解をおそれずにひと言でいえば「パラメータにしたがってランダムに変動するデータを解析するための数学の一分野」です．すなわち，ベイズモデル、生成AIの数学的動作原理です． 日進月歩の勢いで発展を遂げる機械学習の研究成果を各自の専門領域に取り入れるには，これらの中で道具として使われている確率過程の基礎的な知識が必要不可欠です．本書では，数学的な厳密性は犠牲としながらも，機械学習の最新の結果を理解するために最低限必要と思われる内容にしぼって，確率過程について説明しています． このような方におすすめ 理工系および情報系の学部上級生～博士前期過程の大学院生 関連する業務に携わる企業の研究開発者や，実験データ解析等にかかわる他分野の研究者の方々 主要目次 第1章 確率論の基礎 第2章 確率積分と確率微分方程式 第3章 マルコフ過程の性質 第4章 確率過程とベイズモデル 第5章 確率過程と機械学習 第6章 実問題への応用 付録 サンプルコード...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 最小の努力で、最大の学びがここにある！・境界分野が面白い！ 基礎から最先端まで、骨太の一冊！・機械学習に不可欠な基礎知識が身につく。・おだやかではない。かつてこれほどの教科書があっただろうか。...',\n",
       " 'あらゆる予測モデルを解釈する4つの手法PFI、PD、ICE、SHAP/特徴量の重要度/特徴量と予測値の関係性/インスタンスごとの異質性/予測の理由―そのモデルの振る舞いを説明できますか?...',\n",
       " 'Hugging Face Transformersを使った自然言語処理の解説書。大規模モデルを学習しスケールする方法を紹介。...',\n",
       " '最短経路で平易に理解できる、今までにない入門書！ ベイズ主義機械学習（ベイズ学習）の基本原理にのっとり、「モデルの構築→推論の導出」という一貫した手順でアルゴリズムの作り方を解説。どこまでも分かりやすい！...',\n",
       " '★機械学習を「工学」として熟成していくために★ 【推薦の言葉】 AIブームの3回目は、機械学習技術が牽引してきた。業務や生活の 中で使われるようになるにつれて、現場や社会における課題に直面 している。機械学習工学を生み出した著者らによる本書は、技術と 現場をつなぎ、普及させていくための羅針盤となる貴重な一冊である。 ――浦本直彦氏(三菱ケミカルグループ、元・人工知能学会会長) 注目の新領域「機械学習工学」の入門書。まずはこの一冊から始めよう！ 機械学習ソフトウェアの開発・テスト・運用の方法論を体系的に俯瞰できる。 開発現場で試行錯誤しているエンジニアはもちろん、エンジニアと協働している人すべてに読んでほしい。 【主な内容】 巻頭言（丸山宏・PFN） 第1部 機械学習工学とは 第1章 機械学習工学（中川裕志・理化学研究所、石川冬樹・国立情報学研究所） 第2部 機械学習システムの開発・運用マネジメント 第2章 機械学習システムの開発とその検証プロジェクト（竹内広宜・武蔵大学） 第3章 機械学習システムの運用（堀内新吾、土橋昌・株式会社エヌ・ティ・ティ・データ） 第3部 機械学習システムの開発技術と倫理 第4章 機械学習デザインパターン（鷲崎弘宜・早稲田大学） 第5章 品質のとらえ方と管理（石川冬樹・国立情報学研究所） 第6章 機械学習モデルの説明法（原聡・大阪大学） 第7章 AI倫理（中川裕志・理化学研究所） 第4部 機械学習と知財・契約 第8章 機械学習と知財・契約（柿沼太一・弁護士法人STORIA） 第5部 機械学習工学の今後 第9章 今後に向けて（石川冬樹・国立情報学研究所） 付録A 模擬裁判の紹介（柿沼太一・弁護士法人STORIA）...',\n",
       " '平均値のｔ検定、重回帰分析、時系列分析など、社会科学において頻繁に使用される分析手法を取り上げ、データに欠測が生じている場合に多重代入法を用いてどのように欠測データを処理していけばよいかを具体的に解説する。 ※この電子書籍は固定レイアウト型で配信されております。固定レイアウト型は文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 一般的に調査・観測データには欠測が生じることが多く、適切な欠測データの処理をしなければ、解析結果に偏りが生じることがある。多重代入法は、尤度解析法と並んで最も汎用的な欠測データ解析法であるが、これまでの書籍では理論的な解説が主で、実際の応用事例や具体的な手順の記述が少なかった。そのため、実証分析を行う社会科学者や実務者が多重代入法を実際に活用することにはハードルがあった。 本書は、ワンポイントとして代入法を中心に解説している。平均値のt検定、重回帰分析、ロジスティック回帰分析、時系列分析、パネルデータ分析といった社会科学において頻繁に使用される分析手法に関して、データに欠測が生じている場合に、多重代入法を用いてどのように欠測データを処理していけばよいかを具体的に示している。 事例で扱ったデータとRコードが掲載されているので、読者は本書に示された手順を再現しながら、欠測データの解析法を学んでいくことができる。主に、ウェブ上で入手可能な実データで解説しているので、実践的な技能が身につく。本書は、座学として単に読むだけでなく、ぜひコンピュータ上で実際に処理を体験して欲しい。それが、欠測データの解析法を理解し、修得する近道である。...',\n",
       " '記述なし',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 いま最も注目されている機械学習手法である深層学習（ディープラーニング）を、トップ研究者が解説した。基礎から、SGD、自己符号化器、CNN、RNN、ボルツマンマシンまでと、盛りだくさん。軽快な語り口なので、無理なく理解できる！...',\n",
       " '◆ベストセラーの改訂版。最高最強のバイブルが大幅にパワーアップ！！◆ ・トランスフォーマー、グラフニューラルネットワーク、生成モデルなどをはじめ、各手法を大幅に加筆。 ・深層学習のさまざまな課題と、その対策についても詳しく解説。 [本書まえがきより抜粋] ないもの（＝理論）ねだりをしても仕方がありません．それでも皆が研究を進めるのは，そうすることに意義があるからです．なぜうまく働くのか，なぜそうすべきか，数学的な証明はなくても，正しい説明は必ずあるはずです．それを手にできれば，目の前の課題を解決するのに，また次に進むべき道を知るうえで役に立つでしょう． そこで本書では，それぞれの方法について，今の時点で最も納得できる説明をきちんと与えることにこだわりました．名前の通った方法であっても，理屈が成り立たない，あるいは役に立たない方法や考え方については，はっきりそう書きました．著者の主観といわれても仕方がない場合もあるかもしれませんが，そのほうが有益であると信じています． また，現在の深層学習の広がりを把握できるように，定番となった問題・方法に加えて，重要だと思われる問題については，必ずしもそれほど有名でない方法も含めてなるべく網羅するようにしました．その取捨選択には，深層学習が実践的技術であることを踏まえ，実用性を最も重視しました．そこには，この間に著者が企業の実務家たちと行ってきた共同研究での経験が反映されています． [主な内容] 第1章 はじめに 第2章 ネットワークの基本構造 第3章 確率的勾配降下法 第4章 誤差逆伝播法 第5章 畳み込みニューラルネットワーク 第6章 系列データのためのネットワーク 第7章 集合・グラフのためのネットワークと注意機構 第8章 推論の信頼性 第9章 説明と可視化 第10章 いろいろな学習方法 第11章 データが少ない場合の学習 第12章 生成モデル...',\n",
       " '応用(機械翻訳、文書要約、対話、質問応答)に焦点を当て、深層学習の利用方法を解説。「実装上の工夫」など実践的な内容が充実!...',\n",
       " '第三次人工知能（AI）ブームの中核的役割を果たす深層学習（ディープ・ラーニング）は，その高い信頼性と汎用性ゆえに様々な領域に応用されていく一方で，「なぜうまくいくのか」すなわち「なぜ優れた性能を発揮するのか」ということは分かっていない．深層学習の原理を数学的に解明するという難題に，気鋭の研究者が挑む．...',\n",
       " '深層強化学習のモデルやアルゴリズム、その他のノウハウを紹介するテキスト。汎化性を向上させるノウハウや深層強化学習が実応用でどのように使われるかという観点に着目して解説。 ※この電子書籍は固定レイアウト型で配信されております。固定レイアウト型は文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 深層強化学習は、強化学習と深層学習の組み合わせである。この研究分野の発展により、従来機械で扱う範疇ではなかった広範囲の複雑な意思決定問題を解けるようになってきた。深層強化学習はヘルスケア、ロボティクス、スマートグリッド、金融工学、その他さまざまな領域において、新たな応用の可能性を切り拓きつつある。本書は、そのような深層強化学習に関し、強化学習の基礎から始まり、深層強化学習の主要なアルゴリズムや最先端の話題まで、豊富な参考文献も含めて幅広く網羅している。特に本書は、汎化性を向上させるノウハウや深層強化学習が実応用でどのように使われるかという観点に着目して執筆されている。 機械学習の基礎知識を有する大学生・大学院生や企業の研究者・技術者が、深層強化学習の概要を効率的に勉強したいと思ったときの最初の一冊として推薦できる構成となっている。 原著:An Introduction to Deep Reinforcement Learning、 2019...',\n",
       " '記述なし',\n",
       " '本書は、シャノン理論について、ユニバーサル符号化を中心に、その全体をタイプ(type)の理論によって解説したものである。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '注目の最新AI技術！深層強化学習の開発手法がわかる！ 第一線で活躍する著者陣の書下ろしによる待望の1冊！ 【本書の目的】 AlphaGo（アルファ碁）でも利用されている深層強化学習。 AIサービスのみならずロボティクス分野でもその応用が期待されています。 本書は、AI開発に携わる第一線の著者陣が深層強化学習の開発手法について書き下ろした注目の1冊です。 【本書の特徴】 第1部では、まず、深層強化学習の概要について説明します。 次いで、強化学習の基礎（Q学習、方策勾配法、Actor-Critic法）と深層学習の基礎（CNN、RNN、LSTM）を解説します。 さらに、簡単な例題として倒立振子制御を取り上げ、DQNとActor-Critic法による実装例を紹介します。 第2部では、具体的な応用例として3つのアプローチを実装込みで解説します。 1つ目は、連続動作制御です。ヒューマノイドシミュレータの2足歩行制御を試みます。 2つ目は、パズル問題の解法です。巡回セールスマン問題（TSP）やルービックキューブの解探索について説明します。 3つ目は、系列データ生成です。文書生成（SeqGAN）やニューラルネットワークのアーキテクチャ探索（ENAS）を解説します。 全体を通して、行動の制御を担うエージェントのモデル化と、方策ベースの強化学習によるエージェントの学習法について学ぶことができます。 【読者が得られること】 深層強化学習による開発手法を学ぶことができます。 【対象読者】 深層強化学習を学びたい理工学生・エンジニア...',\n",
       " '第一線のAIエンジニアによる 実プロジェクトの経験に裏打ちされた 「自然言語処理」のツボをここに集約! 【本書の目的】 本書は、Pythonを利用して、人工知能分野で注目されている 自然言語の分析手法を解説した書籍です。 従来技術と新技術を比較しつつ、 「インデックス化」「エンティティ抽出」「関係抽出」 「構文解析」「評価・感情・概念分析」を網羅。 Pythonによるプログラムや、APIの利用、 商用サービス(IBM Watson)や OSS(Mecab/Elasticsearch/Word2Vec)の利用など、 実践的な手法を解説します。 また最終章で話題のBERTについて解説します。 【本書の特徴】 本書は全体で5章構成になっています。 第1章:テキスト分析の概要をユーザ―目線、エンジニア目線の両方から丁寧に解説します。 第2章:テキスト分析のタスクを上げ、実際の分析までの具体的な方法を解説します。 第3章:AIの発達する前から利用されていたテキスト分析の手法について、 MecabやElasticsearchといったOSSを利用して解説します。 第4章:IBM社のWatson APIのAI技術を利用したテキスト分析手法を解説します。 第5章:Word2VecというOSSを利用した分析手法や、話題のBERTについて解説します。 【対象読者】 自然言語処理を学びたい理工学生・エンジニア 【著者プロフィール】 赤石雅典(あかいし・まさのり) 1987年日本アイ・ビー・エムに入社。東京基礎研究所で数式処理システムの研究開発に従事する。 1993年にSE部門に異動し、主にオープン系システムのインフラ設計・構築を担当。 2013年よりスマーターシティ事業、2016年8月にワトソン事業部に異動し、今に至る。 現在は、Watson Studio / Watson OpenScaleなどデータサイエンス系製品の提案活動が主体。 江澤美保(えざわ・みほ) 株式会社クレスコ。企業向けWebポータル製品の開発、大規模事務管理の海外移管プロジェクト、 決済サービスのフィールドエンジニア等を経て先端技術の法人営業に転向。 2015 年よりIBM Watsonに携わり、経営層へのWatson導入提案を多く経験。 現在は企業のAI導入支援を手掛けるAIコンサルタント・エンジニアとして活動中。 2019年よりIBM Champion。 ※本電子書籍は同名出版物を底本として作成しました。記載内容は印刷出版当時のものです。 ※印刷出版再現のため電子書籍としては不要な情報を含んでいる場合があります。 ※印刷出版とは異なる表記・表現の場合があります。予めご了承ください。 ※プレビューにてお手持ちの電子端末での表示状態をご確認の上、商品をお買い求めください。 (翔泳社)...',\n",
       " '★★管理職も技術者も必読！「機械学習」のやさしい活用法★★ 機械学習プロジェクトの上手な進め方、機械学習を活用するときに気をつけること、活用事例などをていねいに解説。 「機械学習を作る側」と「機械学習活用する側」との橋渡しとなる一冊！ [本書で学べること］ ・そもそも機械学習で何ができるのか？ ・現場への適切な組み込み方法は？ ・どうやって精度を保証するのか？ ・実運用を見すえたときに確認すべき部分は？ [主な内容] 第1章 本書の使い方 第1部 機械学習の基礎 第2章 機械学習とは何か 第3章 機械学習手法の種類と基礎 第4章 機械学習のタスク 第2部 機械学習の利活用 第5章 機械学習は一般企業でも活用できる 第6章 機械学習を現場で活用するには 第7章 機械学習の適用事例 第8章 実運用に耐えうる機械学習モデルの構築 第9章 機械学習モデルの説明性...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '豊富な実例を用いたプレゼン英語の入門編...',\n",
       " '実例を駆使して理科系のプレゼン英語を解説...',\n",
       " '「このデータが証拠となる」はprovideで表現するのが正解。「方法やプロセスの特徴」を述べるにはinvolveを使う。同じ「合う」でも、fitとmatch、accommodateはどう使い分ける?議論に不可欠なassume、「説明や定義」で活躍するbe動詞から、条件が「有利に働く」favor、分析を「受ける」subjectまで。辞書では見つからない意味・用法がわかり、科学英語の読み書きに必要な英語力が身につく「超実践的」活用辞典。...',\n",
       " '創薬や医療、農業、環境問題に情報科学が果たす役割と実際の手法がわかる。生命科学の基礎のキソからスタートする親切な設計。検定の多重度に対する新しい対応法を紹介した。配列解析における推定量設計を古典的方法から最新情報まで解説する。...',\n",
       " '生成型ディープラーニングの解説。人間にしかできないと思われていた創造的な作業を機械に行わせる技術の基礎から応用までを学ぶ。...',\n",
       " '基礎的な理論から、深層学習をはじめとする最新手法までを網羅し、発展著しい分野を俯瞰できるまたとない一冊。...',\n",
       " '気になるところからするする読める。異常や変化を実際に検知する現実世界の分析者向け。アルゴリズムとその活用例を広範囲に紹介。考え方やモデルの「気持ち」を丁寧に解説。...',\n",
       " 'ウェブ上でのユーザ行動を数理的に分析...',\n",
       " '本書は確率モデル―確率現象を数学的に表現したモデル―を扱うための基礎、つまり確率論・確率過程の入門書。工学や経営科学、物理学や社会学などさまざまな分野で発生する確率現象を取り扱うための基礎的な道具を提供している。特に金融工学における価格過程を視野に入れて解説した。学生やビジネスマンを対象とした、入門のための一冊。...',\n",
       " '本書は、確率統計現象に本質的なエントロピーの役割をクローズアップすることを目的として書かれたものである。確率統計学の古典的な大数の法則やスターリングの公式にエントロピーが登場する場面を見た後、条件つきエントロピーや相互情報量の概念を導入し、これら諸概念の意味を詳しく勉強し、後半では、情報理論の重要な基本問題にこれら諸量がかかわってくる様子を見る。最後の章だけは少し違い、確率概念に基づかないで、一つの文字系列に対してエントロピーが定義できることを示し、符号化の考え方が適用できることを示す。...',\n",
       " '公認会計士の受験科目ともなった確率・統計を,理系だけでなく文系の学生を対象にやさしく解説...',\n",
       " '「基本」は深く、いつも新しい。詳細な記述で数学のパワフルさが実感できる。「知っている」「この程度だろう」の思い込みを覆す新しい話題満載。数式、アルゴリズム、用語がなぜそうなっているか腑に落ちる。...',\n",
       " '確率統計を丁寧に解説した教科書...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '相次ぐ事故で、技術・安全大国崩壊の危機感が漂い、リスクの定量的評価法や管理・調整を効率的に行うための実践方法が、切実に求められている。本書は、こうした定量的リスク解析の数理的な基礎と方法をできるだけ平易に与える。第1部では、リスク解析の歴史を概観する。第2部では、不確定性を定量的に扱うための確率論や統計的推定の基礎がまとめられている。第3部では、基本的な故障木及び事象木解析を簡単な例題で学ぶ。また、様々なリスク解析の新手法が紹介されている。第4部では、意思決定の理論、影響図、プロジェクトリスク管理、不確定性解析、リスク管理・調整などの新しい応用解析の方法が紹介されている。確率論的リスク解析と数学的基礎を学ぶための好著。...',\n",
       " '「因果性」「実在/反実在」「価値判断」の三つの問題群に着目し、科学哲学と科学の接点を探る。...',\n",
       " '本書は、誤り訂正符号あるいは誤り検出符号を中心として、それに最近の符号理論におけるいくつかの重要な論題をあわせて記述したものである。対象としては主として大学院修士課程の学生を考え、したがってなるべく基礎的な事項に重点を置き記述している。しかし実際に符号理論の応用を目的とする研究者ならびに技術者にも直接役立ち得るように、豊富に図や表を挿入し、説明が難解にならないようにしている。...',\n",
       " '教科書としても研究用参考書としても有用であることを目標とし、組合せ最適化における重要な概念、理論的成果、アルゴリズムを解説。...',\n",
       " '記述なし',\n",
       " '「線形代数」というきれいな数学は、歴史的には「行列代数」「行列の代数」という呼び名でそもそも始まった。この本は、統計ユーザーが線形統計モデルや多変量解析での応用に必要とする線形代数の基礎を、具体的に行列を使って解き明かした入門書である。この本では原則として全ての定理に証明がついている。また、それぞれの理論の道筋の途中で読者がつまづきやすい箇所には、「どこがわかればわかるのか」を明らかにしつつ「なぜそうなるのか」が懇切丁寧に解説されている。...',\n",
       " '「線形代数」というきれいな数学は、歴史的には「行列代数」「行列の代数」という呼び名でそもそも始まった。この本は、統計ユーザーが線形統計モデルや多変量解析での応用に必要とする線形代数の基礎を、具体的に行列を使って解き明かした入門書である。この本では原則として全ての定理に証明がついている。また、それぞれの理論の道筋の途中で読者がつまづきやすい箇所には、「どこがわかればわかるのか」を明らかにしつつ「なぜそうなるのか」が懇切丁寧に解説されている。...',\n",
       " '記述なし',\n",
       " 'ロジスティック回帰モデル、一般化線形モデル、混合分布モデルまで、この一冊で！ ・確率分布、推定、検定などの基本的な内容から、ロジスティック回帰モデル、一般化線形モデル、混合分布モデルまでを一冊で解説した、稀有の入門書 ・Rによるデータ分析例およびコードを多く掲載！ 【データサイエンス入門シリーズ】 第2期として、以下の2点を同時刊行! 『統計モデルと推測』松井秀俊・小泉和之（著）竹村彰通（編） 『Pythonで学ぶアルゴリズムとデータ構造』辻真吾（著）下平英寿（編） 第3期の刊行は2020年2月の予定(^o^)/ 【「巻頭言」より抜粋】 文部科学省は「数理及びデータサイエンスに係る教育強化拠点」6 大学(北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学)を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。 本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。 データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 ――編集委員長 竹村彰通(滋賀大学データサイエンス学部学部長、教授) 【推薦の言葉】 データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。 ――北川源四郎(東京大学特任教授、元統計数理研究所所長) 国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。 ――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授) ※この商品は紙の書籍のページを画像にした電子書籍です。文字だけを拡大することはできませんので、タブレットサイズの端末での閲読を推奨します。また、文字列のハイライトや検索、辞書の参照、引用などの機能も使用できません。...',\n",
       " '著者の長年にわたる統計学研究・教育を通して得られた統計学の基礎や統計学における哲学、思想をまとめた。統計学は活用されるさまざまな目的に応じて独自の着眼点や手法を扱う。本書では、それらの理論背景を一貫した著者の目線で貫き、欠落しがちな倫理観から始め、数学の個別手法に入り込み過ぎることなく実践的なシミュレーションまでまとめる...',\n",
       " '著者の長年にわたる統計学研究・教育を通して得られた統計学の基礎や統計学における哲学、思想をまとめた。統計学は活用されるさまざまな目的に応じて独自の着眼点や手法を扱う。本書では、それらの理論背景を一貫した著者の目線で貫き、欠落しがちな倫理観から始め、数学の個別手法に入り込み過ぎることなく実践的なシミュレーションまでまとめる...',\n",
       " 'エッセンスをまとめ,統計での使い方を解説...',\n",
       " '統計学に必要な線形代数を初歩から網羅...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '実際に役立つ観点から、実用性を意識して解説。識別系と特徴抽出系をバランスよく、図表を多用して丁寧に記述。...',\n",
       " '現代は、膨大なデータを適切な形で集め、さらにそれらを蓄積することが可能な時代である。そのようななか、両テーマが共有する関心は、データから本質をつかみ、さらにそれを活かすことである。前者では、データの背後に潜む真実・法則の探求が出発点である。また後者は、与えられたデータをいかに手なずけ利用するかに力点がある。実際、情報理論や統計科学と呼ばれる分野では、統計的な考察によりモデルを適切に選択することや、データを取り扱いやすい形にまとめる作業などを通して、未知の情報源から来る出力系列から情報源モデルを推測するための方法論が発展してきた。それが人工知能の一分野である機械学習と呼ばれる理論の基礎となっている。さらにまた、このような機械学習において生まれた概念が、情報理論や統計科学に新しい刺激を与え、フィードバックをもたらしている。このような状況を踏まえながら、共通点をもちつつ相補的な2つのテーマについて紹介してゆくことが本書の目的である。...',\n",
       " '統計学の理論的基礎である不偏推定に焦点を当てて解説。データサイエンスにかかわる学生・研究者を対象に、自学できるよう配慮した。...',\n",
       " 'セミパラメトリックアプローチを因果探索法の「真打ち」として幅広く紹介。代表的手法LiNGAMをその考案者である著者が解説。...',\n",
       " 'データの因果関係を認識する方法とその数理...',\n",
       " '第2回杉山明子賞[出版賞](日本行動計量学会“出版賞”)受賞! 日本行動計量学会総会(2012年9月15日(土)新潟県立大学)におきまして、黒木学先生が、杉山明子賞(出版賞) を受賞しました。受賞理由は、本書の翻訳出版によるものです。 本書は、「人工知能分野の巨人のひとり」(Richard Korf)として数えられ、統計的因果推論の世界的権威である人工知能研究者Judea Pearlによって書かれた\"Causality-Models、 Reasoning and Inference-\"(Cambridge Univ. Press)の邦訳である。 本書は、既存の統計的因果推論の教科書とは異なり、因果推論の背後にある哲学的考え方を踏まえながら、グラフィカルモデル、反事実モデル、構造モデルといった数理解析法を用いて因果関係の解明に迫るという独創的なアイデアに基づいて執筆されている。また、統計科学と因果推論との類似点や相違点も詳しく記述されており、因果的関連尺度と統計的関連尺度を結びつけるための数理的基盤の整備も行われている。 本書の特徴として、邦訳出版にあたって原著者から提供された最新の研究情報も追加されており、統計的因果推論に関する最新のフレームワークを体系的に理解するのに役立つよう配慮されていることがあげられる。そのため、統計的因果推論の主要課題である 1.観察された結果に対する原因の究明、2.観察データに基づく因果的効果の定量的評価、3.観察データに基づく因果メカニズムの解明、に関心を持つ読者に対して、大きなインパクトを与えるだろう。...',\n",
       " 'Rubinの提唱した潜在的結果変数の枠組みによる統計的因果推論の理論と実装を統一的にカバー。欠測データの因果推論も扱う。...',\n",
       " '本とWebコンテンツを融合した電子教科書...',\n",
       " '※この商品はタブレットなど大きいディスプレイを備えた端末で読むことに適しています。また、文字だけを拡大することや、文字列のハイライト、検索、辞書の参照、引用などの機能が使用できません。 丁寧な説明が感動的！ しっかり、よくわかる！どのような学習アルゴリズムが効率的かを見極めるには、確率論・統計学に根ざした基礎が不可欠。カーネル法、ＳＶＭ、ブースティングなど、重要概念を丁寧に記述した。学習手法をしっかり理解して使いこなせるようになる。...',\n",
       " '記述なし',\n",
       " '本とWebコンテンツを融合した電子教科書...',\n",
       " '統計的機械学習の数理100問のPython版!数式を導き、ソースプログラムを追い、具体的に手を動かしてスキルを身につける!...',\n",
       " 'データサイエンスの基盤として重要な逐次推定に焦点をあて解説。和書での類書はほとんどなく,例を多用して自学できるようまとめた。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '論文作成から学会発表までをこれ1冊で!...',\n",
       " '本書では、英語で論文を書くのに必要な表現を中心に、英語論文の構成の仕方から論文作成上のルールまで、この1冊で英語論文の書き方のノウハウが分かるよう構成されています。また、実用的であり、利用者の使いやすさを追求した参考書でもあります。...',\n",
       " '記述なし',\n",
       " 'Nグラムモデル、隠れマルコフモデル、確率文法、最大エントロピー法...確率・統計的観点からの言語のモデル化と応用を詳説。この刺激的な分野への、最初の系統的入門書。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '大量データ時代の統計科学の手法とは...',\n",
       " '計算統計において広く応用され重要性の高い三つの計算手法を適用例を交えながら詳しく解説。...',\n",
       " '脳はいかにして複雑な感覚を処理し、精巧に身体を操るのか?計算理論/表現とアルゴリズム/実装の観点から、脳の理解に挑む“計算論的神経科学”(computational neuroscience)。運動制御・感覚処理の研究を中心に、その数学的基礎から分野の最前線までを概観。...',\n",
       " '基礎的な考え方を丁寧に説明し,時系列モデルを実際のデータに応用する際に必要な知識を紹介...',\n",
       " '誤り訂正技術の理論体系である符号理論。その符号理論に、代数的な側面と確率的側面から迫る。情報科学、数学、物理といったさまざまな分野につながる符号理論のおもしろさを本書で体感してほしい。...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '★まさにバイブル！★ 転移学習は、従来の機械学習の方法では解決することが困難な要請や課題をうまく取り扱うための方法です。深層学習の登場以降、事前学習済みモデルの利用が容易になり、転移学習が広く用いられるようになってきた。 本書では、転移学習の基本概念から、ドメイン適応、事前学習済みモデル、知識蒸留、マルチタスク学習、メタ学習、継続学習などをていねいに解説。この一冊から始めよう！ 【主な内容】 第1部 転移学習への導入 第1章 機械学習から転移学習へ 第2章 転移学習の基本概念 第2部 転移学習の基礎 第3章 ドメイン適応の理論 第4章 データに基づくドメイン適応の基礎 第5章 モデルに基づくドメイン適応の展開 第6章 事前学習済みモデル 第3部 転移学習の展開 第7章 知識蒸留 第8章 マルチタスク学習 第9章 メタ学習 第10章 少数ショット学習 第11章 ドメイン汎化 第12章 継続学習 第13章 強化学習における転移学習 付録A 深層ニューラルネットワークと生成モデルの基礎...',\n",
       " '記述なし',\n",
       " '記述なし',\n",
       " '大規模データの存在を背景に、データに語らしめる方法として確立しつつある関係データ学習。その具体的手順を示しながら解説する。...',\n",
       " '記述なし',\n",
       " '本書は現在注目を集めている「集合知」をテーマにした書籍です。機械学習のアルゴリズムと統計を使ってウェブのユーザが生み出した膨大なデータを分析、解釈する方法を、基礎から分かりやすく解説します。本書で紹介するのは「購入・レンタルした商品の情報を利用した推薦システム」、「膨大なデータから類似したアイテムを発見し、クラスタリングする方法」など。del.icio.us、eBayなどが公開しているWeb APIを使用した解説も本書の大きな特徴です。本書のサンプルコードは可読性に優れたPythonを使用していますが、他の言語のプログラマでも理解しやすいようにアルゴリズムを解説しています。日本語版ではYahoo!日本語形態素解析Webサービスを利用した日本語テキスト処理について加筆しました。...',\n",
       " '非線形計画問題の最適化理論を丁寧に解説...',\n",
       " '基礎理論はコンパクトにまとめ、「耐雑音」「話者認識」「深層学習」についてたっぷり解説。音声認識分野がこれ一冊で学べる!...',\n",
       " '記述なし',\n",
       " '理系のレポート作成や論文執筆の定番「LaTeX」の使い方が一冊でわかる!これだけ読めばレポートを簡単に書き始められます。...',\n",
       " '理系のレポート作成や論文執筆の定番「LaTeX」の使い方が一冊でわかる!これだけ読めばレポートを簡単に書き始められます。...',\n",
       " '現代社会を支える根幹技術をPythonで！ Pythonプログラミングのスキルアップにも最適！ 名著『Pythonスタートブック』の著者である辻真吾氏が書き下ろす至極の入門書！ ソートやグラフ構造など基本的な内容から、乱択アルゴリズムや数論、ブロックチェーンの仕組みなどの幅広い話題までを解説。コードはWeb公開（ https://github.com/tsjshg/pyalgdata）。 【データサイエンス入門シリーズ】 第2期として、以下の2点を刊行! 『統計モデルと推測』松井秀俊・小泉和之（著）竹村彰通（編） 『Pythonで学ぶアルゴリズムとデータ構造』辻真吾（著）下平英寿（編） 【「巻頭言」より抜粋】 文部科学省は「数理及びデータサイエンスに係る教育強化拠点」6 大学(北海道大学、東京大学、滋賀大学、京都大学、大阪大学、九州大学)を選定し、拠点校は「数理・データサイエンス教育強化拠点コンソーシアム」を設立して、全国の大学に向けたデータサイエンス教育の指針や教育コンテンツの作成をおこなっています。 本シリーズは、コンソーシアムのカリキュラム分科会が作成したデータサイエンスに関するスキルセットに準拠した標準的な教科書シリーズを目指して編集されました。またコンソーシアムの教材分科会委員の先生方には各巻の原稿を読んでいただき、貴重なコメントをいただきました。 データサイエンスは、従来からの統計学とデータサイエンスに必要な情報学の二つの分野を基礎としますが、データサイエンスの教育のためには、データという共通点からこれらの二つの分野を融合的に扱うことが必要です。この点で本シリーズは、これまでの統計学やコンピュータ科学の個々の教科書とは性格を異にしており、ビッグデータの時代にふさわしい内容を提供します。本シリーズが全国の大学で活用されることを期待いたします。 ――編集委員長 竹村彰通(滋賀大学データサイエンス学部学部長、教授) 【推薦の言葉】 データサイエンスの教育の場や実践の場で利用されることを強く意識して、動機付け、題材選び、説明の仕方、例題選びが工夫されており、従来の教科書とは異なりデータサイエンス向けの入門書となっている。 ――北川源四郎(東京大学特任教授、元統計数理研究所所長) 国を挙げて先端IT人材の育成を迅速に進める必要があり、本シリーズはまさにこの目的に合致しています。本シリーズが、初学者にとって信頼できる案内人となることを期待します。 ――杉山将(理化学研究所革新知能統合研究センターセンター長、東京大学教授)...']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"].fillna(\"記述なし\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abetaichi/master/app/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.28449714, -0.14825982,  0.08901754, ..., -0.583057  ,\n",
       "        -0.0719334 , -0.16652516],\n",
       "       [-0.2517601 , -0.09318337, -0.8791181 , ..., -0.19825548,\n",
       "        -0.54661006, -0.03238581],\n",
       "       [-0.6428728 ,  0.49908695, -0.08862256, ..., -0.35763887,\n",
       "        -0.4635009 ,  0.19611615],\n",
       "       ...,\n",
       "       [-0.2744395 ,  0.16816276, -0.17471284, ..., -0.6563951 ,\n",
       "        -0.08829963, -0.23920502],\n",
       "       [-0.2744395 ,  0.16816276, -0.17471284, ..., -0.6563951 ,\n",
       "        -0.08829963, -0.23920502],\n",
       "       [-0.13540842, -0.1565875 , -0.3880207 , ..., -0.33481348,\n",
       "        -0.29473698,  0.10787263]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers.models import Transformer, Pooling\n",
    "\n",
    "transformer = Transformer('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "pooling = Pooling(transformer.get_word_embedding_dimension(), pooling_mode_mean_tokens=False, pooling_mode_cls_token=True, pooling_mode_max_tokens=False)\n",
    "model = SentenceTransformer(modules=[transformer, pooling])\n",
    "\n",
    "sentences = df[\"description\"].fillna(\"記述なし\").values.tolist()\n",
    "embeddings = model.encode(sentences)\n",
    "embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28449714, -0.14825982,  0.08901754, ..., -0.583057  ,\n",
       "        -0.0719334 , -0.16652516],\n",
       "       [-0.2517601 , -0.09318337, -0.8791181 , ..., -0.19825548,\n",
       "        -0.54661006, -0.03238581],\n",
       "       [-0.6428728 ,  0.49908695, -0.08862256, ..., -0.35763887,\n",
       "        -0.4635009 ,  0.19611615],\n",
       "       ...,\n",
       "       [-0.2744395 ,  0.16816276, -0.17471284, ..., -0.6563951 ,\n",
       "        -0.08829963, -0.23920502],\n",
       "       [-0.2744395 ,  0.16816276, -0.17471284, ..., -0.6563951 ,\n",
       "        -0.08829963, -0.23920502],\n",
       "       [-0.13540842, -0.1565875 , -0.3880207 , ..., -0.33481348,\n",
       "        -0.29473698,  0.10787263]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# 今日の日付を取得\n",
    "today_date = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# embeddingsをnumpy形式で保存\n",
    "file_name = f\"embeddings_{today_date}.npy\"\n",
    "np.save(file_name, embeddings)\n",
    "\n",
    "# 保存したファイルを確認\n",
    "loaded_embeddings = np.load(file_name)\n",
    "loaded_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 検索部分をテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_title</th>\n",
       "      <th>search_authors</th>\n",
       "      <th>search_publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>publisher</th>\n",
       "      <th>published_date</th>\n",
       "      <th>description</th>\n",
       "      <th>page_count</th>\n",
       "      <th>categories</th>\n",
       "      <th>language</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>use_title</th>\n",
       "      <th>use_author</th>\n",
       "      <th>use_publisher</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Pythonでスラスラわかるベイズ推論「超」入門</td>\n",
       "      <td>赤石雅典，須山敦志</td>\n",
       "      <td>講談社</td>\n",
       "      <td>Ｐｙｔｈｏｎでスラスラわかる　ベイズ推論「超」入門</td>\n",
       "      <td>赤石雅典, 須山敦志</td>\n",
       "      <td>講談社</td>\n",
       "      <td>2023-11-23</td>\n",
       "      <td>★数学とプログラミングを対比させながら、一歩一歩わかりやすく！ 実務に即してPyMC5プログ...</td>\n",
       "      <td>298.0</td>\n",
       "      <td>Computers</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=H5nlE...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>強化学習</td>\n",
       "      <td>森村哲郎</td>\n",
       "      <td>講談社</td>\n",
       "      <td>強化学習</td>\n",
       "      <td>森村哲郎</td>\n",
       "      <td>講談社</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>理論は裏切らない！ ・強化学習で必要になる数理を広くカバーした。・一貫したていねいな解説なの...</td>\n",
       "      <td>381.0</td>\n",
       "      <td>Technology &amp; Engineering</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=QmmuD...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ベイズ深層学習</td>\n",
       "      <td>須山敦志</td>\n",
       "      <td>講談社</td>\n",
       "      <td>ベイズ深層学習</td>\n",
       "      <td>須山敦志</td>\n",
       "      <td>講談社</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>「読んでいて本当に心地がいい」と大好評の前著『ベイズ推論による機械学習入門』からの第２弾！ ...</td>\n",
       "      <td>314.0</td>\n",
       "      <td>Computers</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=2360D...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Pythonではじめるベイズ機械学習入門</td>\n",
       "      <td>森賀新，木田悠歩，須山敦志</td>\n",
       "      <td>講談社</td>\n",
       "      <td>Ｐｙｔｈｏｎではじめるベイズ機械学習入門</td>\n",
       "      <td>森賀新, 木田悠歩, 須山敦志</td>\n",
       "      <td>講談社</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>★確率的プログラミング言語がすぐに使える！★ ・Pythonでのコーディングを前提に、PyM...</td>\n",
       "      <td>359.0</td>\n",
       "      <td>Computers</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=lfqLE...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>これならわかる機械学習入門</td>\n",
       "      <td>富谷昭夫</td>\n",
       "      <td>講談社</td>\n",
       "      <td>これならわかる機械学習入門</td>\n",
       "      <td>富谷昭夫</td>\n",
       "      <td>講談社</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>【道具として使いこなす！】 膨大な観測データから普遍的な法則を抽出する手法とは？ 高校数学レ...</td>\n",
       "      <td>289.0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>ja</td>\n",
       "      <td>http://books.google.com/books/content?id=Yz81E...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 search_title search_authors search_publisher  \\\n",
       "46   Pythonでスラスラわかるベイズ推論「超」入門      赤石雅典，須山敦志              講談社   \n",
       "244                      強化学習           森村哲郎              講談社   \n",
       "176                   ベイズ深層学習           須山敦志              講談社   \n",
       "44       Pythonではじめるベイズ機械学習入門  森賀新，木田悠歩，須山敦志              講談社   \n",
       "78              これならわかる機械学習入門           富谷昭夫              講談社   \n",
       "\n",
       "                         title          authors publisher published_date  \\\n",
       "46   Ｐｙｔｈｏｎでスラスラわかる　ベイズ推論「超」入門       赤石雅典, 須山敦志       講談社     2023-11-23   \n",
       "244                       強化学習             森村哲郎       講談社     2019-05-23   \n",
       "176                    ベイズ深層学習             須山敦志       講談社     2019-08-08   \n",
       "44        Ｐｙｔｈｏｎではじめるベイズ機械学習入門  森賀新, 木田悠歩, 須山敦志       講談社     2022-05-26   \n",
       "78               これならわかる機械学習入門             富谷昭夫       講談社     2021-03-29   \n",
       "\n",
       "                                           description  page_count  \\\n",
       "46   ★数学とプログラミングを対比させながら、一歩一歩わかりやすく！ 実務に即してPyMC5プログ...       298.0   \n",
       "244  理論は裏切らない！ ・強化学習で必要になる数理を広くカバーした。・一貫したていねいな解説なの...       381.0   \n",
       "176  「読んでいて本当に心地がいい」と大好評の前著『ベイズ推論による機械学習入門』からの第２弾！ ...       314.0   \n",
       "44   ★確率的プログラミング言語がすぐに使える！★ ・Pythonでのコーディングを前提に、PyM...       359.0   \n",
       "78   【道具として使いこなす！】 膨大な観測データから普遍的な法則を抽出する手法とは？ 高校数学レ...       289.0   \n",
       "\n",
       "                   categories language  \\\n",
       "46                  Computers       ja   \n",
       "244  Technology & Engineering       ja   \n",
       "176                 Computers       ja   \n",
       "44                  Computers       ja   \n",
       "78                Mathematics       ja   \n",
       "\n",
       "                                             thumbnail  use_title  use_author  \\\n",
       "46   http://books.google.com/books/content?id=H5nlE...        1.0         1.0   \n",
       "244  http://books.google.com/books/content?id=QmmuD...        1.0         1.0   \n",
       "176  http://books.google.com/books/content?id=2360D...        1.0         1.0   \n",
       "44   http://books.google.com/books/content?id=lfqLE...        1.0         1.0   \n",
       "78   http://books.google.com/books/content?id=Yz81E...        1.0         1.0   \n",
       "\n",
       "     use_publisher  errors  \n",
       "46             1.0       0  \n",
       "244            0.0       0  \n",
       "176            1.0       0  \n",
       "44             1.0       0  \n",
       "78             1.0       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# クエリの入力\n",
    "query = \"★数学とプログラミングを対比させながら、一歩一歩わかりやすく！ 実務に即してPyMC5プログラミングでベイズ推論を使いこなせるようになる。 最初の一冊として、データサイエンティストにおすすめ！ 【サポートサイト】 https://github.com/makaishi2/python_bayes_intro 【主な内容】 第1章 確率分布を理解する 1.1 ベイズ推論における確率分布の必要性 1.2 確率変数と確率分布 1.3 離散分布と連続分布 1.4 PyMCによる確率モデル定義とサンプリング 1.5 サンプリング結果分析 1.6 確率分布とPyMCプログラミングの関係 第2章 よく利用される確率分布 2.1 ベルヌーイ分布（pm.Bernoulliクラス） 2.2 二項分布（pm.Binomial クラス） 2.3 正規分布（pm.Normal クラス） 2.4 一様分布（pm.Uniform クラス） 2.5 ベータ分布（pm.Beta クラス） 2.6 半正規分布（pm.HalfNormal クラス） 第3章 ベイズ推論とは 3.1 ベイズ推論利用の目的 3.2 問題設定 3.3 最尤推定による解法 3.4 ベイズ推論による解法 3.5 ベイズ推論の精度を上げる方法 3.6 ベイズ推論の活用例 第4章 はじめてのベイズ推論実習 4.1 問題設定 (再掲) 4.2 最尤推定 4.3 ベイズ推論 (確率モデル定義） 4.4 ベイズ推論 (サンプリング） 4.5 ベイズ推論 (結果分析） 4.6 ベイズ推論 (二項分布バージョン） 4.7 ベイズ推論 (試行回数を増やす） 4.8 ベイズ推論 (事前分布の変更） 4.9 ベータ分布で直接確率分布を求める 第5章 ベイズ推論プログラミング 5.1 データ分布のベイズ推論 5.2 線形回帰のベイズ推論 5.3 階層ベイズモデル 5.4 潜在変数モデル 第6章 ベイズ推論の業務活用事例 6.1 ABテストの効果検証 6.2 ベイズ回帰モデルによる効果検証 6.3 IRT (Item Response Theory）によるテスト結果評価...\"\n",
    "\n",
    "# クエリのembeddingを計算\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "# コサイン類似度を計算\n",
    "similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "\n",
    "# 類似度の上位n件のインデックスを取得\n",
    "top_n = 5  # 取得する上位n件の数\n",
    "top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "df.iloc[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28449714, -0.14825982,  0.08901754, ..., -0.583057  ,\n",
       "        -0.0719334 , -0.16652516],\n",
       "       [-0.2517601 , -0.09318337, -0.8791181 , ..., -0.19825548,\n",
       "        -0.54661006, -0.03238581],\n",
       "       [-0.6428728 ,  0.49908695, -0.08862256, ..., -0.35763887,\n",
       "        -0.4635009 ,  0.19611615],\n",
       "       ...,\n",
       "       [-0.2744395 ,  0.16816276, -0.17471284, ..., -0.6563951 ,\n",
       "        -0.08829963, -0.23920502],\n",
       "       [-0.2744395 ,  0.16816276, -0.17471284, ..., -0.6563951 ,\n",
       "        -0.08829963, -0.23920502],\n",
       "       [-0.13540842, -0.1565875 , -0.3880207 , ..., -0.33481348,\n",
       "        -0.29473698,  0.10787263]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
